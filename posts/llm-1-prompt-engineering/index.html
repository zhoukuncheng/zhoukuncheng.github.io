<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>LLM Learning Series 1. Prompt Engineering | zhoukuncheng's Personal Blog</title>
<meta name=keywords content="LLM,Prompt Engineering"><meta name=description content='Mastering the Art of LLM Prompts Large Language Models (LLMs) like GPT-4 and Claude possess remarkable capabilities. However, unlocking their full potential requires effective communication through well-crafted prompts. This guide delves into the art of prompt engineering, offering a step-by-step approach – from fundamental principles to advanced techniques – to harness the true power of LLMs.
Step 1: Choosing the Optimal Model Latest and Greatest: Newer models like GPT-4 Turbo offer significant advantages over predecessors like GPT-3.5 Turbo, including smoother natural language understanding. For simpler tasks, extensive prompt engineering may be less crucial.
Benchmarking: Utilize resources like LLM leaderboards and benchmark results to compare models and identify the best fit for your specific needs.
Examples:
For nuanced language translation, GPT-4 Turbo&rsquo;s contextual understanding is likely superior to older models. For tasks that require both capabilities and speed, the Llama-3-70b open-source model is an excellent option. Step 2: Establishing Clear Communication Clarity and Specificity Explicit Instructions: Treat the LLM as a collaborator requiring clear direction. Define the task, desired outcome, format, style, and output length explicitly, avoiding ambiguity.
Contextual Grounding: Provide relevant background information and context to guide the LLM towards the desired response, considering the intended audience and purpose.
Separation of Concerns: Clearly separate instructions from context using ### or """.'><meta name=author content><link rel=canonical href=https://zhoukuncheng.github.io/posts/llm-1-prompt-engineering/><link crossorigin=anonymous href=/assets/css/stylesheet.5cfc680b1eeaeef9efbced92d46c2a9e876b72ee14fba85846afc4cff9e6e6f8.css integrity="sha256-XPxoCx7q7vnvvO2S1Gwqnodrcu4U+6hYRq/Ez/nm5vg=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://zhoukuncheng.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://zhoukuncheng.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://zhoukuncheng.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://zhoukuncheng.github.io/apple-touch-icon.png><link rel=mask-icon href=https://zhoukuncheng.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://zhoukuncheng.github.io/posts/llm-1-prompt-engineering/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-GH88YSLNJN"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-GH88YSLNJN")}</script><meta property="og:title" content="LLM Learning Series 1. Prompt Engineering"><meta property="og:description" content='Mastering the Art of LLM Prompts Large Language Models (LLMs) like GPT-4 and Claude possess remarkable capabilities. However, unlocking their full potential requires effective communication through well-crafted prompts. This guide delves into the art of prompt engineering, offering a step-by-step approach – from fundamental principles to advanced techniques – to harness the true power of LLMs.
Step 1: Choosing the Optimal Model Latest and Greatest: Newer models like GPT-4 Turbo offer significant advantages over predecessors like GPT-3.5 Turbo, including smoother natural language understanding. For simpler tasks, extensive prompt engineering may be less crucial.
Benchmarking: Utilize resources like LLM leaderboards and benchmark results to compare models and identify the best fit for your specific needs.
Examples:
For nuanced language translation, GPT-4 Turbo&rsquo;s contextual understanding is likely superior to older models. For tasks that require both capabilities and speed, the Llama-3-70b open-source model is an excellent option. Step 2: Establishing Clear Communication Clarity and Specificity Explicit Instructions: Treat the LLM as a collaborator requiring clear direction. Define the task, desired outcome, format, style, and output length explicitly, avoiding ambiguity.
Contextual Grounding: Provide relevant background information and context to guide the LLM towards the desired response, considering the intended audience and purpose.
Separation of Concerns: Clearly separate instructions from context using ### or """.'><meta property="og:type" content="article"><meta property="og:url" content="https://zhoukuncheng.github.io/posts/llm-1-prompt-engineering/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-04-27T11:11:34+08:00"><meta property="article:modified_time" content="2024-04-27T11:11:34+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="LLM Learning Series 1. Prompt Engineering"><meta name=twitter:description content='Mastering the Art of LLM Prompts Large Language Models (LLMs) like GPT-4 and Claude possess remarkable capabilities. However, unlocking their full potential requires effective communication through well-crafted prompts. This guide delves into the art of prompt engineering, offering a step-by-step approach – from fundamental principles to advanced techniques – to harness the true power of LLMs.
Step 1: Choosing the Optimal Model Latest and Greatest: Newer models like GPT-4 Turbo offer significant advantages over predecessors like GPT-3.5 Turbo, including smoother natural language understanding. For simpler tasks, extensive prompt engineering may be less crucial.
Benchmarking: Utilize resources like LLM leaderboards and benchmark results to compare models and identify the best fit for your specific needs.
Examples:
For nuanced language translation, GPT-4 Turbo&rsquo;s contextual understanding is likely superior to older models. For tasks that require both capabilities and speed, the Llama-3-70b open-source model is an excellent option. Step 2: Establishing Clear Communication Clarity and Specificity Explicit Instructions: Treat the LLM as a collaborator requiring clear direction. Define the task, desired outcome, format, style, and output length explicitly, avoiding ambiguity.
Contextual Grounding: Provide relevant background information and context to guide the LLM towards the desired response, considering the intended audience and purpose.
Separation of Concerns: Clearly separate instructions from context using ### or """.'><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://zhoukuncheng.github.io/posts/"},{"@type":"ListItem","position":2,"name":"LLM Learning Series 1. Prompt Engineering","item":"https://zhoukuncheng.github.io/posts/llm-1-prompt-engineering/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"LLM Learning Series 1. Prompt Engineering","name":"LLM Learning Series 1. Prompt Engineering","description":"Mastering the Art of LLM Prompts Large Language Models (LLMs) like GPT-4 and Claude possess remarkable capabilities. However, unlocking their full potential requires effective communication through well-crafted prompts. This guide delves into the art of prompt engineering, offering a step-by-step approach – from fundamental principles to advanced techniques – to harness the true power of LLMs.\nStep 1: Choosing the Optimal Model Latest and Greatest: Newer models like GPT-4 Turbo offer significant advantages over predecessors like GPT-3.5 Turbo, including smoother natural language understanding. For simpler tasks, extensive prompt engineering may be less crucial.\nBenchmarking: Utilize resources like LLM leaderboards and benchmark results to compare models and identify the best fit for your specific needs.\nExamples:\nFor nuanced language translation, GPT-4 Turbo\u0026rsquo;s contextual understanding is likely superior to older models. For tasks that require both capabilities and speed, the Llama-3-70b open-source model is an excellent option. Step 2: Establishing Clear Communication Clarity and Specificity Explicit Instructions: Treat the LLM as a collaborator requiring clear direction. Define the task, desired outcome, format, style, and output length explicitly, avoiding ambiguity.\nContextual Grounding: Provide relevant background information and context to guide the LLM towards the desired response, considering the intended audience and purpose.\nSeparation of Concerns: Clearly separate instructions from context using ### or \u0026quot;\u0026quot;\u0026quot;.","keywords":["LLM","Prompt Engineering"],"articleBody":"Mastering the Art of LLM Prompts Large Language Models (LLMs) like GPT-4 and Claude possess remarkable capabilities. However, unlocking their full potential requires effective communication through well-crafted prompts. This guide delves into the art of prompt engineering, offering a step-by-step approach – from fundamental principles to advanced techniques – to harness the true power of LLMs.\nStep 1: Choosing the Optimal Model Latest and Greatest: Newer models like GPT-4 Turbo offer significant advantages over predecessors like GPT-3.5 Turbo, including smoother natural language understanding. For simpler tasks, extensive prompt engineering may be less crucial.\nBenchmarking: Utilize resources like LLM leaderboards and benchmark results to compare models and identify the best fit for your specific needs.\nExamples:\nFor nuanced language translation, GPT-4 Turbo’s contextual understanding is likely superior to older models. For tasks that require both capabilities and speed, the Llama-3-70b open-source model is an excellent option. Step 2: Establishing Clear Communication Clarity and Specificity Explicit Instructions: Treat the LLM as a collaborator requiring clear direction. Define the task, desired outcome, format, style, and output length explicitly, avoiding ambiguity.\nContextual Grounding: Provide relevant background information and context to guide the LLM towards the desired response, considering the intended audience and purpose.\nSeparation of Concerns: Clearly separate instructions from context using ### or \"\"\".\nExamples as Guides: Demonstrate the desired output format and style with well-chosen examples.\nCueing: Use short phrases like “Key points:”, “Summary:”, or “Code:” to indicate the desired output format.\nExamples:\nInstead of “Create a blog post,” specify “Write a 500-word blog post about renewable energy’s impact, targeting industry professionals.” For a poem generation task, you might specify the desired tone, rhyme scheme, and theme. Few-Shot Learning Provide a few examples demonstrating the desired output format and style to reduce ambiguity and set clear expectations.\nExamples:\nPrompt: Translate these sentences to Spanish:\n“The cat sat on the mat.” - “El gato se sentó en la alfombra.” “The dog barked at the mailman.” - “El perro ladró al cartero.” “The children played in the park.” Expected Output: “Los niños jugaron en el parque.”\nPrompt: Write product descriptions in a witty and engaging style:\nProduct: Noise-cancelling headphones Description: “Silence the world and get lost in your own soundscape with these noise-cancelling headphones. Perfect for escaping the daily grind or focusing on your work.” Product: Travel backpack Description: “This travel backpack is your ultimate adventure companion. With its spacious compartments and durable design, it’s ready to explore the world with you.” Product: Smartwatch Description: Expected Output: “This smartwatch is more than just a timepiece; it’s your personal assistant, fitness tracker, and notification hub, all wrapped up in one sleek design.”\nStep 3: Guiding the LLM’s Thought Process Chain-of-Thought (CoT) Prompting For complex reasoning tasks, guide the LLM step-by-step through the thought process, encouraging it to break down the problem and generate a logical sequence of reasoning steps leading to the answer.\nExamples:\nProblem: John has 5 apples, gives 2 to Mary, then buys 5 more. How many apples does he have now?\nCoT Prompt: “John starts with 5 apples. After giving 2 to Mary, he has 3 left. Buying 5 more gives him 3 + 5 = 8 apples.”\nProblem: Who was the most decorated (maximum medals) individual athlete in the 2000 Sydney Olympic games? Take a step-by-step approach in your response, cite sources and give reasoning before sharing the final answer in the below format: ANSWER is: CoT Prompt:\nStep 1: Determine the year of the Sydney Olympic games. The Sydney Olympic games were held in the year 2000. Step 2: Find a list of individual athletes who won multiple medals in the 2000 Sydney Olympics. According to the official website of the Olympic Games, there were several individual athletes who won multiple medals in the 2000 Sydney Olympics. Some of the notable names include: • Ian Thorpe (Australia) - 3 gold, 2 silver, 0 bronze • Pieter van den Hoogenband (Netherlands) - 2 gold, 0 silver, 2 bronze • Lenny Krayzelburg (USA) - 3 gold, 0 silver, 0 bronze • Inge de Bruijn (Netherlands) - 3 gold, 1 silver, 0 bronze Step 3: Determine the athlete with the most medals. After reviewing the list of individual athletes who won multiple medals in the 2000 Sydney Olympics, we can see that the athlete with the most medals is Ian Thorpe from Australia, who won a total of 5 medals (3 gold and 2 silver). Therefore, the ANSWER is: Ian Thorpe. Self-Consistency Generate multiple outputs and choose the most consistent or frequent response to mitigate biases and enhance reliability.\nExamples:\nWhen seeking historical facts, generate multiple explanations and select the most frequent or seemingly accurate one based on consensus. Similarly, for creative tasks like story generation, generating multiple drafts and choosing the most engaging or consistent narrative can be beneficial. Prompt:\nQ: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today? A: We start with 15 trees. Later we have 21 trees. The difference must be the number of trees they planted. So, they must have planted 21 - 15 = 6 trees. The answer is 6. Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot? A: There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars. The answer is 5. Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total? A: Leah had 32 chocolates and Leah’s sister had 42. That means there were originally 32 + 42 = 74 chocolates. 35 have been eaten. So in total they still have 74 - 35 = 39 chocolates. The answer is 39. Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny? A: Jason had 20 lollipops. Since he only has 12 now, he must have given the rest to Denny. The number of lollipops he has given to Denny must have been 20 - 12 = 8 lollipops. The answer is 8. Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now? A: He has 5 toys. He got 2 from mom, so after that he has 5 + 2 = 7 toys. Then he got 2 more from dad, so in total he has 7 + 2 = 9 toys. The answer is 9. Q: There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room? A: There are 4 days from monday to thursday. 5 computers were added each day. That means in total 4 * 5 = 20 computers were added. There were 9 computers in the beginning, so now there are 9 + 20 = 29 computers. The answer is 29. Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he have at the end of wednesday? A: Michael initially had 58 balls. He lost 23 on Tuesday, so after that he has 58 - 23 = 35 balls. On Wednesday he lost 2 more so now he has 35 - 2 = 33 balls. The answer is 33. Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left? A: She bought 5 bagels for $3 each. This means she spent $15. She has $8 left. Q: When I was 6 my sister was half my age. Now I’m 70 how old is my sister? A: Output 1:\nWhen I was 6 my sister was half my age, so she was 3. Now I am 70, so she is 70 - 3 = 67. The answer is 67. Output 2:\nWhen the narrator was 6, his sister was half his age, which is 3. Now that the narrator is 70, his sister would be 70 - 3 = 67 years old. The answer is 67. Output 3:\nWhen I was 6 my sister was half my age, so she was 3. Now I am 70, so she is 70/2 = 35. The answer is 35. Task Decomposition Break down complex tasks into smaller, more manageable subtasks using techniques like prompt chaining.\nExamples:\nTo solve a complex math problem, first ask the LLM to identify the problem type, then solve each part step-by-step, and finally, combine the parts to reach the solution.\nPrompt Chaining for Code Generation:\nPrompt 1: “Write a Python function that takes a list of numbers as input.” Prompt 2 (based on output of Prompt 1): “Modify the function to calculate the sum of all numbers in the list.” Prompt 3 (based on output of Prompt 2): “Add functionality to the function to return the average of the numbers in the list.” Step 4: Enhancing Capabilities and Control System Prompt and Role System Prompt: Define the LLM’s behavior, role, personality, and limitations.\nRole Assignment: Assign a specific role to focus responses and tailor the language style.\nExamples:\n“You are a friendly nutritionist providing a balanced meal plan for someone with a gluten allergy.” “You are a seasoned travel guide creating a one-week itinerary for exploring the historical sites of Rome.” Retrieval Augmentation (RAG) RAG: Combine LLMs with external knowledge sources like databases or APIs for improved accuracy and up-to-date information. Examples:\n“Using current stock market data from the XYZ API, analyze and predict next week’s trend for tech stocks.” “Access the latest research papers on climate change from a scientific database and summarize the key findings and proposed solutions.” Temperature and Top_p Temperature: Control the randomness and creativity of the output.\nTop_p: Adjust the probability distribution of the next token to influence the diversity of generated text.\nExamples:\nFor creative writing, higher temperatures encourage more varied and unexpected plot twists. For factual reports, lower temperatures ensure more straightforward and consistent information. For generating different creative text formats, like poems, scripts, or musical pieces, adjusting temperature and top_p can lead to diverse styles and structures within the chosen format. References https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering\nhttps://platform.openai.com/docs/guides/prompt-engineering\nhttps://docs.anthropic.com/claude/docs/prompt-engineering\nhttps://www.promptingguide.ai/\n","wordCount":"1738","inLanguage":"en","datePublished":"2024-04-27T11:11:34+08:00","dateModified":"2024-04-27T11:11:34+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://zhoukuncheng.github.io/posts/llm-1-prompt-engineering/"},"publisher":{"@type":"Organization","name":"zhoukuncheng's Personal Blog","logo":{"@type":"ImageObject","url":"https://zhoukuncheng.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://zhoukuncheng.github.io/ accesskey=h title="zhoukuncheng's Personal Blog (Alt + H)">zhoukuncheng's Personal Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://zhoukuncheng.github.io/ title=Home><span>Home</span></a></li><li><a href=https://zhoukuncheng.github.io/posts/ title=Archive><span>Archive</span></a></li><li><a href=https://zhoukuncheng.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://zhoukuncheng.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://zhoukuncheng.github.io/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>LLM Learning Series 1. Prompt Engineering</h1><div class=post-meta><span title='2024-04-27 11:11:34 +0800 +0800'>April 27, 2024</span></div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#mastering-the-art-of-llm-prompts aria-label="Mastering the Art of LLM Prompts">Mastering the Art of LLM Prompts</a><ul><li><a href=#step-1-choosing-the-optimal-model aria-label="Step 1: Choosing the Optimal Model">Step 1: Choosing the Optimal Model</a></li><li><a href=#step-2-establishing-clear-communication aria-label="Step 2: Establishing Clear Communication">Step 2: Establishing Clear Communication</a><ul><li><a href=#clarity-and-specificity aria-label="Clarity and Specificity">Clarity and Specificity</a></li><li><a href=#few-shot-learning aria-label="Few-Shot Learning">Few-Shot Learning</a></li></ul></li><li><a href=#step-3-guiding-the-llms-thought-process aria-label="Step 3: Guiding the LLM&amp;rsquo;s Thought Process">Step 3: Guiding the LLM&rsquo;s Thought Process</a><ul><li><a href=#chain-of-thought-cot-prompting aria-label="Chain-of-Thought (CoT) Prompting">Chain-of-Thought (CoT) Prompting</a></li><li><a href=#self-consistency aria-label=Self-Consistency>Self-Consistency</a></li><li><a href=#task-decomposition aria-label="Task Decomposition">Task Decomposition</a></li></ul></li><li><a href=#step-4-enhancing-capabilities-and-control aria-label="Step 4: Enhancing Capabilities and Control">Step 4: Enhancing Capabilities and Control</a><ul><li><a href=#system-prompt-and-role aria-label="System Prompt and Role">System Prompt and Role</a></li><li><a href=#retrieval-augmentation-rag aria-label="Retrieval Augmentation (RAG)">Retrieval Augmentation (RAG)</a></li><li><a href=#temperature-and-top_p aria-label="Temperature and Top_p">Temperature and Top_p</a></li></ul></li><li><a href=#references aria-label=References>References</a></li></ul></li></ul></div></details></div><div class=post-content><h2 id=mastering-the-art-of-llm-prompts>Mastering the Art of LLM Prompts<a hidden class=anchor aria-hidden=true href=#mastering-the-art-of-llm-prompts>#</a></h2><p>Large Language Models (LLMs) like GPT-4 and Claude possess remarkable capabilities. However, unlocking their full potential requires effective communication through well-crafted prompts. This guide delves into the art of prompt engineering, offering a step-by-step approach – from fundamental principles to advanced techniques – to harness the true power of LLMs.</p><h3 id=step-1-choosing-the-optimal-model>Step 1: Choosing the Optimal Model<a hidden class=anchor aria-hidden=true href=#step-1-choosing-the-optimal-model>#</a></h3><ul><li><p><strong>Latest and Greatest:</strong> Newer models like GPT-4 Turbo offer significant advantages over predecessors like GPT-3.5 Turbo, including smoother natural language understanding. For simpler tasks, extensive prompt engineering may be less crucial.</p></li><li><p><strong>Benchmarking:</strong> Utilize resources like <a href=https://chat.lmsys.org/?leaderboard>LLM leaderboards</a> and benchmark results to compare models and identify the best fit for your specific needs.</p></li></ul><p><img loading=lazy src=https://github.com/zhoukuncheng/zhoukuncheng.github.io/assets/5327960/84e5da2a-f2ef-49b2-9137-eef2b8aaa9ed alt=image></p><p><strong>Examples:</strong></p><ul><li>For nuanced language translation, GPT-4 Turbo&rsquo;s contextual understanding is likely superior to older models.</li><li>For tasks that require both capabilities and speed, the Llama-3-70b open-source model is an excellent option.</li></ul><h3 id=step-2-establishing-clear-communication>Step 2: Establishing Clear Communication<a hidden class=anchor aria-hidden=true href=#step-2-establishing-clear-communication>#</a></h3><h4 id=clarity-and-specificity>Clarity and Specificity<a hidden class=anchor aria-hidden=true href=#clarity-and-specificity>#</a></h4><ul><li><p><strong>Explicit Instructions:</strong> Treat the LLM as a collaborator requiring clear direction. Define the task, desired outcome, format, style, and output length explicitly, avoiding ambiguity.</p></li><li><p><strong>Contextual Grounding:</strong> Provide relevant background information and context to guide the LLM towards the desired response, considering the intended audience and purpose.</p></li><li><p><strong>Separation of Concerns:</strong> Clearly separate instructions from context using <code>###</code> or <code>"""</code>.</p></li><li><p><strong>Examples as Guides:</strong> Demonstrate the desired output format and style with well-chosen examples.</p></li><li><p><strong>Cueing:</strong> Use short phrases like &ldquo;Key points:&rdquo;, &ldquo;Summary:&rdquo;, or &ldquo;Code:&rdquo; to indicate the desired output format.</p></li></ul><p><strong>Examples:</strong></p><ul><li>Instead of &ldquo;Create a blog post,&rdquo; specify &ldquo;Write a 500-word blog post about renewable energy&rsquo;s impact, targeting industry professionals.&rdquo;</li><li>For a poem generation task, you might specify the desired tone, rhyme scheme, and theme.</li></ul><h4 id=few-shot-learning>Few-Shot Learning<a hidden class=anchor aria-hidden=true href=#few-shot-learning>#</a></h4><p>Provide a few examples demonstrating the desired output format and style to reduce ambiguity and set clear expectations.</p><p><strong>Examples:</strong></p><ul><li><p><strong>Prompt:</strong> Translate these sentences to Spanish:</p><ul><li>&ldquo;The cat sat on the mat.&rdquo; - &ldquo;El gato se sentó en la alfombra.&rdquo;</li><li>&ldquo;The dog barked at the mailman.&rdquo; - &ldquo;El perro ladró al cartero.&rdquo;</li><li>&ldquo;The children played in the park.&rdquo;</li></ul></li><li><p><strong>Expected Output:</strong> &ldquo;Los niños jugaron en el parque.&rdquo;</p></li><li><p><strong>Prompt:</strong> Write product descriptions in a witty and engaging style:</p><ul><li><strong>Product:</strong> Noise-cancelling headphones</li><li><strong>Description:</strong> &ldquo;Silence the world and get lost in your own soundscape with these noise-cancelling headphones. Perfect for escaping the daily grind or focusing on your work.&rdquo;</li><li><strong>Product:</strong> Travel backpack</li><li><strong>Description:</strong> &ldquo;This travel backpack is your ultimate adventure companion. With its spacious compartments and durable design, it&rsquo;s ready to explore the world with you.&rdquo;</li><li><strong>Product:</strong> Smartwatch</li><li><strong>Description:</strong></li></ul></li><li><p><strong>Expected Output:</strong> &ldquo;This smartwatch is more than just a timepiece; it&rsquo;s your personal assistant, fitness tracker, and notification hub, all wrapped up in one sleek design.&rdquo;</p></li></ul><h3 id=step-3-guiding-the-llms-thought-process>Step 3: Guiding the LLM&rsquo;s Thought Process<a hidden class=anchor aria-hidden=true href=#step-3-guiding-the-llms-thought-process>#</a></h3><h4 id=chain-of-thought-cot-prompting>Chain-of-Thought (CoT) Prompting<a hidden class=anchor aria-hidden=true href=#chain-of-thought-cot-prompting>#</a></h4><p>For complex reasoning tasks, guide the LLM step-by-step through the thought process, encouraging it to break down the problem and generate a logical sequence of reasoning steps leading to the answer.</p><p><strong>Examples:</strong></p><ul><li><p><strong>Problem:</strong> John has 5 apples, gives 2 to Mary, then buys 5 more. How many apples does he have now?</p></li><li><p><strong>CoT Prompt:</strong> &ldquo;John starts with 5 apples. After giving 2 to Mary, he has 3 left. Buying 5 more gives him 3 + 5 = 8 apples.&rdquo;</p></li><li><p><strong>Problem:</strong> Who was the most decorated (maximum medals) individual athlete in the 2000 Sydney Olympic games? Take a step-by-step approach in your response, cite sources and give reasoning before sharing the final answer in the below format: ANSWER is: <code>&lt;name></code></p></li><li><p><strong>CoT Prompt:</strong></p></li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>Step 1: Determine the year of the Sydney Olympic games. The Sydney Olympic games were held in the year 2000.  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>Step 2: Find a list of individual athletes who won multiple medals in the 2000 Sydney Olympics.  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>According to the official website of the Olympic Games, there were several individual athletes who won multiple medals in the 2000 Sydney Olympics. Some of the notable names include:  
</span></span><span class=line><span class=cl>• Ian Thorpe (Australia) - 3 gold, 2 silver, 0 bronze  
</span></span><span class=line><span class=cl>• Pieter van den Hoogenband (Netherlands) - 2 gold, 0 silver, 2 bronze  
</span></span><span class=line><span class=cl>• Lenny Krayzelburg (USA) - 3 gold, 0 silver, 0 bronze  
</span></span><span class=line><span class=cl>• Inge de Bruijn (Netherlands) - 3 gold, 1 silver, 0 bronze  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>Step 3: Determine the athlete with the most medals. After reviewing the list of individual athletes who won multiple medals in the 2000 Sydney Olympics, we can see that the athlete with the most medals is Ian Thorpe from Australia, who won a total of 5 medals (3 gold and 2 silver).  
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>Therefore, the ANSWER is: Ian Thorpe.
</span></span></code></pre></div><h4 id=self-consistency>Self-Consistency<a hidden class=anchor aria-hidden=true href=#self-consistency>#</a></h4><p>Generate multiple outputs and choose the most consistent or frequent response to mitigate biases and enhance reliability.</p><p><strong>Examples:</strong></p><ul><li>When seeking historical facts, generate multiple explanations and select the most frequent or seemingly accurate one based on consensus.</li><li>Similarly, for creative tasks like story generation, generating multiple drafts and choosing the most engaging or consistent narrative can be beneficial.</li></ul><p><em>Prompt:</em></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done,
</span></span><span class=line><span class=cl>there will be 21 trees. How many trees did the grove workers plant today?
</span></span><span class=line><span class=cl>A: We start with 15 trees. Later we have 21 trees. The difference must be the number of trees they planted.
</span></span><span class=line><span class=cl>So, they must have planted 21 - 15 = 6 trees. The answer is 6.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?
</span></span><span class=line><span class=cl>A: There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars. The answer is 5.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?
</span></span><span class=line><span class=cl>A: Leah had 32 chocolates and Leah’s sister had 42. That means there were originally 32 + 42 = 74
</span></span><span class=line><span class=cl>chocolates. 35 have been eaten. So in total they still have 74 - 35 = 39 chocolates. The answer is 39.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops
</span></span><span class=line><span class=cl>did Jason give to Denny?
</span></span><span class=line><span class=cl>A: Jason had 20 lollipops. Since he only has 12 now, he must have given the rest to Denny. The number of
</span></span><span class=line><span class=cl>lollipops he has given to Denny must have been 20 - 12 = 8 lollipops. The answer is 8.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does
</span></span><span class=line><span class=cl>he have now?
</span></span><span class=line><span class=cl>A: He has 5 toys. He got 2 from mom, so after that he has 5 + 2 = 7 toys. Then he got 2 more from dad, so
</span></span><span class=line><span class=cl>in total he has 7 + 2 = 9 toys. The answer is 9.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Q: There were nine computers in the server room. Five more computers were installed each day, from
</span></span><span class=line><span class=cl>monday to thursday. How many computers are now in the server room?
</span></span><span class=line><span class=cl>A: There are 4 days from monday to thursday. 5 computers were added each day. That means in total 4 * 5 =
</span></span><span class=line><span class=cl>20 computers were added. There were 9 computers in the beginning, so now there are 9 + 20 = 29 computers.
</span></span><span class=line><span class=cl>The answer is 29.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many
</span></span><span class=line><span class=cl>golf balls did he have at the end of wednesday?
</span></span><span class=line><span class=cl>A: Michael initially had 58 balls. He lost 23 on Tuesday, so after that he has 58 - 23 = 35 balls. On
</span></span><span class=line><span class=cl>Wednesday he lost 2 more so now he has 35 - 2 = 33 balls. The answer is 33.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?
</span></span><span class=line><span class=cl>A: She bought 5 bagels for $3 each. This means she spent $15. She has $8 left.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Q: When I was 6 my sister was half my age. Now I’m 70 how old is my sister?
</span></span><span class=line><span class=cl>A:
</span></span></code></pre></div><p><em>Output 1:</em></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>When I was 6 my sister was half my age, so she was 3. Now I am 70, so she is 70 - 3 = 67. The answer is 67.
</span></span></code></pre></div><p><em>Output 2:</em></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>When the narrator was 6, his sister was half his age, which is 3. Now that the narrator is 70, his sister would be 70 - 3 = 67 years old. The answer is 67.
</span></span></code></pre></div><p><em>Output 3:</em></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>When I was 6 my sister was half my age, so she was 3. Now I am 70, so she is 70/2 = 35. The answer is 35.
</span></span></code></pre></div><h4 id=task-decomposition>Task Decomposition<a hidden class=anchor aria-hidden=true href=#task-decomposition>#</a></h4><p>Break down complex tasks into smaller, more manageable subtasks using techniques like prompt chaining.</p><p><strong>Examples:</strong></p><ul><li><p>To solve a complex math problem, first ask the LLM to identify the problem type, then solve each part step-by-step, and finally, combine the parts to reach the solution.</p></li><li><p><strong>Prompt Chaining for Code Generation:</strong></p><ol><li><strong>Prompt 1:</strong> &ldquo;Write a Python function that takes a list of numbers as input.&rdquo;</li><li><strong>Prompt 2 (based on output of Prompt 1):</strong> &ldquo;Modify the function to calculate the sum of all numbers in the list.&rdquo;</li><li><strong>Prompt 3 (based on output of Prompt 2):</strong> &ldquo;Add functionality to the function to return the average of the numbers in the list.&rdquo;</li></ol></li></ul><h3 id=step-4-enhancing-capabilities-and-control>Step 4: Enhancing Capabilities and Control<a hidden class=anchor aria-hidden=true href=#step-4-enhancing-capabilities-and-control>#</a></h3><h4 id=system-prompt-and-role>System Prompt and Role<a hidden class=anchor aria-hidden=true href=#system-prompt-and-role>#</a></h4><ul><li><p><strong>System Prompt:</strong> Define the LLM&rsquo;s behavior, role, personality, and limitations.</p></li><li><p><strong>Role Assignment:</strong> Assign a specific role to focus responses and tailor the language style.</p></li></ul><p><strong>Examples:</strong></p><ul><li>&ldquo;You are a friendly nutritionist providing a balanced meal plan for someone with a gluten allergy.&rdquo;</li><li>&ldquo;You are a seasoned travel guide creating a one-week itinerary for exploring the historical sites of Rome.&rdquo;</li></ul><h4 id=retrieval-augmentation-rag>Retrieval Augmentation (RAG)<a hidden class=anchor aria-hidden=true href=#retrieval-augmentation-rag>#</a></h4><ul><li><strong>RAG:</strong> Combine LLMs with external knowledge sources like databases or APIs for improved accuracy and up-to-date information.</li></ul><p><strong>Examples:</strong></p><ul><li>&ldquo;Using current stock market data from the XYZ API, analyze and predict next week&rsquo;s trend for tech stocks.&rdquo;</li><li>&ldquo;Access the latest research papers on climate change from a scientific database and summarize the key findings and proposed solutions.&rdquo;</li></ul><h4 id=temperature-and-top_p>Temperature and Top_p<a hidden class=anchor aria-hidden=true href=#temperature-and-top_p>#</a></h4><ul><li><p><strong>Temperature:</strong> Control the randomness and creativity of the output.</p></li><li><p><strong>Top_p:</strong> Adjust the probability distribution of the next token to influence the diversity of generated text.</p></li></ul><p><strong>Examples:</strong></p><ul><li>For creative writing, higher temperatures encourage more varied and unexpected plot twists. For factual reports, lower temperatures ensure more straightforward and consistent information.</li><li>For generating different creative text formats, like poems, scripts, or musical pieces, adjusting temperature and top_p can lead to diverse styles and structures within the chosen format.</li></ul><h3 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h3><p><a href=https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering>https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering</a><br><a href=https://platform.openai.com/docs/guides/prompt-engineering>https://platform.openai.com/docs/guides/prompt-engineering</a><br><a href=https://docs.anthropic.com/claude/docs/prompt-engineering>https://docs.anthropic.com/claude/docs/prompt-engineering</a><br><a href=https://www.promptingguide.ai/>https://www.promptingguide.ai/</a></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://zhoukuncheng.github.io/tags/llm/>LLM</a></li><li><a href=https://zhoukuncheng.github.io/tags/prompt-engineering/>Prompt Engineering</a></li></ul></footer><script src=https://giscus.app/client.js data-repo=zhoukuncheng/zhoukuncheng.github.io data-repo-id="MDEwOlJlcG9zaXRvcnkyODIxMTA1OTU=" data-category=General data-category-id=DIC_kwDOENCqg84Cexta data-mapping=og:title data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-theme=purple_dark data-lang=en crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2024 <a href=https://zhoukuncheng.github.io/>zhoukuncheng's Personal Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>