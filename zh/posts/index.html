<!doctype html><html lang=zh dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | zhoukuncheng's Personal Blog</title><meta name=keywords content><meta name=description content="Posts - zhoukuncheng's Personal Blog"><meta name=author content="zhoukuncheng"><link rel=canonical href=https://zhoukuncheng.github.io/zh/posts/><link crossorigin=anonymous href=/assets/css/stylesheet.343cc480b9ffc8f04ccbe5e968ad674880cab773ec19905e93033065c1e7a804.css integrity="sha256-NDzEgLn/yPBMy+XpaK1nSIDKt3PsGZBekwMwZcHnqAQ=" rel="preload stylesheet" as=style><link rel=icon href=https://zhoukuncheng.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://zhoukuncheng.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://zhoukuncheng.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://zhoukuncheng.github.io/apple-touch-icon.png><link rel=mask-icon href=https://zhoukuncheng.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://zhoukuncheng.github.io/zh/posts/index.xml title=rss><link rel=alternate hreflang=zh href=https://zhoukuncheng.github.io/zh/posts/><link rel=alternate hreflang=en href=https://zhoukuncheng.github.io/posts/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-GH88YSLNJN"></script><script>var doNotTrack=!1,dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-GH88YSLNJN")}</script><meta property="og:url" content="https://zhoukuncheng.github.io/zh/posts/"><meta property="og:site_name" content="zhoukuncheng's Personal Blog"><meta property="og:title" content="Posts"><meta property="og:description" content="zhoukuncheng's Personal Blog"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Posts"><meta name=twitter:description content="zhoukuncheng's Personal Blog"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://zhoukuncheng.github.io/zh/posts/"}]}</script></head><body class=list id=top><header class=header><nav class=nav><div class=logo><a href=https://zhoukuncheng.github.io/zh/ accesskey=h title="zhoukuncheng's Personal Blog (Alt + H)">zhoukuncheng's Personal Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://zhoukuncheng.github.io/ title=English aria-label=English>En</a></li></ul></div></div><ul id=menu><li><a href=https://zhoukuncheng.github.io/zh/ title=首页><span>首页</span></a></li><li><a href=https://zhoukuncheng.github.io/zh/posts/ title=归档><span class=active>归档</span></a></li><li><a href=https://zhoukuncheng.github.io/zh/tags/ title=标签><span>标签</span></a></li><li><a href=https://zhoukuncheng.github.io/zh/categories/ title=分类><span>分类</span></a></li><li><a href=https://zhoukuncheng.github.io/zh/about/ title=关于><span>关于</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>Posts</h1></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>我的播客之旅：百余档中英文节目分类整理</h2></header><div class=entry-content><p>我的播客之旅 在这个信息爆炸的时代,如何高效地获取知识并持续学习成为了一个重要课题。本文将分享我利用播客进行英语学习和技术视野拓展的经历,希望能为想尝试听播客的朋友提供一些参考。
背景：疫情带来的大片空闲时间 2020年的疫情改变了许多人的工作方式,远程办公和混合办公模式逐渐成为主流。这一变化带来了更多的在家空闲时间和通勤时间。面对中国社会经济前景的不确定性,我决定利用这些时间提升自身竞争力,特别是在英语语言能力方面。
最初,我选择了TED和BBC Global News等热门节目作为学习资源。然而,我很快发现这些内容存在一些局限性:
话题相对单一 语言难度较低 难以满足深入了解英语语言文化的需求 为了突破这些限制,我开始借助搜索引擎和Pocket Casts等播客应用的推荐系统,探索更广阔的播客世界。这一决定开启了我充满惊喜的播客学习之旅。
我的播客清单 经过一段时间的探索和筛选,我的播客订阅列表逐渐形成了以下四大类:
音乐 财经 科技 英语学习 音乐 我的音乐口味比较杂食,涵盖了:
欧美流行乐、摇滚乐 华语流行歌 粤语老歌 日本动漫歌曲 财经 在财经领域,我主要关注以下几类播客:
企业和金融市场的历史故事、分析、新闻
The Economist Planet Money Freakonomics Radio Acquired 投资策略与个人理财
Motley Fool Money We Study Billionaires - The Investor’s Podcast Network The Money To The Masses Podcast MarketPlace 这些播客帮助我了解宏观经济现状、企业发展史、当前的投资策略等。
科技：紧跟技术前沿 作为一名程序员,我特别关注与编程语言、软件开发和网络安全相关的播客:
编程语言专题
Python: Talk Python To Me, Python People Go: Go Time, Go夜聊 JavaScript: JS Party 网站可靠性工程(SRE)
Ship It! 网络安全
...</p></div><footer class=entry-footer><span title='2024-08-18 11:50:04 +0800 +0800'>2024年8月18日</span>&nbsp;·&nbsp;<span>zhoukuncheng</span></footer><a class=entry-link aria-label="post link to 我的播客之旅：百余档中英文节目分类整理" href=https://zhoukuncheng.github.io/zh/posts/my-podcast-collection/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>LLM 学习系列 2. Function Calling</h2></header><div class=entry-content><p>介绍 对于典型的 LLM 交互，单个提示或几轮聊天通常足以获得所需的结果。但是，某些任务需要 LLM 访问其内部知识库之外的信息。例如，获取特定城市今天的天气信息或搜索特定的动漫，这些都需要调用外部函数。
什么是 Function Calling？ LLM 中的 Function Calling（函数调用）使模型能够生成 JSON 对象，从而触发代码中的外部函数。此功能不仅使 LLM 能够连接到外部工具和 API，而且扩展了其执行各种任务的能力。
Function Calling 执行步骤 用户使用工具和用户提示词调用 LLM API： 用户提供提示并指定可用工具。
What is the weather like in San Francisco? 定义工具 Schema
tools = [ { "type": "function", "function": { "name": "get_current_weather", "description": "Get the current weather in a given location", "parameters": { "type": "object", "properties": { "location": { "type": "string", "description": "The city and state, e.g. San Francisco, CA", }, "unit": { "type": "string", "enum": ["celsius", "fahrenheit"]}, }, "required": ["location"], }, }, } ] 定义 Mock 函数
...</p></div><footer class=entry-footer><span title='2024-05-05 16:11:34 +0800 +0800'>2024年5月5日</span>&nbsp;·&nbsp;<span>zhoukuncheng</span></footer><a class=entry-link aria-label="post link to LLM 学习系列 2. Function Calling" href=https://zhoukuncheng.github.io/zh/posts/llm-2-function-calling/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>LLM 学习系列 1：提示工程</h2></header><div class=entry-content><p>掌握 LLM 提示词的艺术 像 GPT-4 和 Claude 这样的大型语言模型 (LLM) 拥有非凡的能力。然而，要释放它们的全部潜力，需要通过精心设计的提示词 (prompts) 进行有效沟通。本指南深入探讨了提示工程 (prompt engineering) 的艺术，提供了一个从基本原则到高级技巧的分步方法，以驾驭 LLM 的真正力量。
第一步：选择最佳模型 最新且最强： 像 GPT-4 Turbo 这样的较新模型相比 GPT-3.5 Turbo 等前代产品提供了显著优势，包括更流畅的自然语言理解能力。对于较简单的任务，通过大量的提示工程来弥补模型能力的必要性可能会降低。
基准测试： 利用 LLM 排行榜 和基准测试结果等资源来比较模型，并找出最适合你特定需求的模型。
示例：
对于细致入微的语言翻译，GPT-4 Turbo 的上下文理解能力可能优于旧模型。 对于既需要能力又需要速度的任务，Llama-3-70b 开源模型是一个绝佳的选择。 第二步：建立清晰的沟通 清晰度和具体性 明确的指令： 将 LLM 视为通过需要清晰指导的合作者。明确定义任务、期望的结果、格式、风格和输出长度，避免歧义。
上下文背景： 提供相关的背景信息和语境，以引导 LLM 做出期望的回应，同时考虑目标受众和目的。
关注点分离： 使用 ### 或 """ 将指令与上下文内容清晰地分隔开。
以示例为向导： 用精选的示例来演示期望的输出格式和风格。
线索提示： 使用短语如 “Key points:"（关键点：）、“Summary:"（摘要：）或 “Code:"（代码：）来指示期望的输出格式。
示例：
不要只说 “写一篇博客文章”，而应指定 “写一篇关于可再生能源影响的 500 字博客文章，目标受众是行业专业人士。” 对于诗歌生成任务，你可以指定期望的基调、韵律和主题。 少样本学习 (Few-Shot Learning) 提供几个展示了期望输出格式和风格的示例，以减少歧义并设定清晰的预期。
...</p></div><footer class=entry-footer><span title='2024-04-27 11:11:34 +0800 +0800'>2024年4月27日</span>&nbsp;·&nbsp;<span>zhoukuncheng</span></footer><a class=entry-link aria-label="post link to LLM 学习系列 1：提示工程" href=https://zhoukuncheng.github.io/zh/posts/llm-1-prompt-engineering/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>借助 LLM 和 Telegram 机器人，让背单词不再枯燥</h2></header><div class=entry-content><p>背英语单词总是 Abandon？ 向多邻国 🦉 取经，让单词主动提醒自己 背单词，在英语学习中实在无法避免，从小学到研究生，甚至部分工作岗位也需要记单词。
但抱着单词书啃，或者手机上一板一眼背单词，效率实在太低。现在 LLM 这么火，为何不利用起来？
毕竟 LLM 中间的 L 就是 Language 的意思，LLM 对付其他严谨任务可能差点意思，但英语等语言可是它的强项，能用技术解决问题，就不要麻烦自己！
本文就来分享一下，怎么用欧路词典 API、LLM 和 Telegram 机器人搞个英语词汇学习助手，让你背单词不再痛苦。
当然，也可能用几天就感觉很烦人，毕竟灵感来自多邻国 App🦉。
项目目标：解放注意力 不用主动去硬背单词，而是让程序代劳，并且要根据单词生成例句和文章，让你更好地理解和记忆。总之，就是让你背单词更轻松、更有效率。
系统架构 欧路词典 API： 欧路词典既可以查词又可以背单词，就选它了。 LLM (比如 Groq)： 大语言模型，可以根据单词生成各种例句、对话甚至文章，让你更好地理解单词的用法。还可以利用它生成符合雅思
IELTS 写作考核标准的文章，帮助你学习英语写作。Groq 是目前容易免费获取的 LLM API，可以选择 Mixtral 8x7b 模型。 Telegram 机器人： Telegram 平台相比微信，QQ 等自由、API 强大，功能丰富，最适合用它来当提醒工具。 格式转换： 由于 Telegram 消息对 Markdown 的限制，和 Telegraph 写作平台对 HTML 标签的限制，我们需要进行格式转换，确保内容能够正确显示。 实现方法 获取生词列表
接口文档： https://my.eudic.net/OpenAPI/doc_api_study
获取所有生词本 接口说明： 请求方式：GET 请求地址：https://api.frdic.com/api/open/v1/studylist/category 本接口用于获取生词本信息 生词本的ID是唯一标识，用于调用其他接口 生成例句和文章
...</p></div><footer class=entry-footer><span title='2024-04-19 00:11:00 +0800 +0800'>2024年4月19日</span>&nbsp;·&nbsp;<span>zhoukuncheng</span></footer><a class=entry-link aria-label="post link to 借助 LLM 和 Telegram 机器人，让背单词不再枯燥" href=https://zhoukuncheng.github.io/zh/posts/llm-vocabulary-reminder/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Traefik 架构与源码分析：深度探索</h2></header><div class=entry-content><p>Traefik 是一个被广泛采用的开源 HTTP 反向代理和负载均衡器，它简化了现代 Web 应用程序的路由和请求负载均衡。它拥有动态配置功能，并支持众多提供商 (providers)，定位为编排复杂部署场景的多功能解决方案。在这篇博文中，我们将深入探讨 Traefik 的架构，并剖析其源代码的关键组件，以便更细致地了解其运行机制。
Traefik 架构：高层概述 在其核心，Traefik 的架构由几个主要组件组成，这些组件协同工作以促进动态路由和负载均衡：
静态配置 (Static Configuration): 这些是 Traefik 的基础设置，包括入口点 (entry points)、提供商 (providers) 和 API 访问配置。它们可以通过文件、命令行参数或环境变量来指定。
动态配置 (Dynamic Configuration): 这涉及可根据基础设施状态进行调整的路由规则、服务和中间件。Traefik 与多种提供商（如 Docker、Kubernetes、Consul Catalog 等）的兼容性突显了其动态特性。
提供商 (Providers): 作为 Traefik 与服务发现机制之间的桥梁，提供商的任务是获取并将动态配置传递给 Traefik。每个提供商都是为集成不同技术（如 Docker、Kubernetes 和 Consul）而定制的。
入口点 (Entry Points): 这些指定了 Traefik 监听入站流量的网络接口（端口和协议）。
路由器 (Routers): 路由器建立通过各种参数（如主机名、路径和头部）匹配传入请求的标准。它们负责将请求引导至适当的服务。
服务 (Services): 服务定义了 Traefik 与处理请求的后端系统进行通信的机制。可以通过不同的负载均衡策略和健康检查对服务进行微调。
中间件 (Middlewares): 作为模块化实体，中间件可以附加到路由器或服务上，启用一系列功能，包括身份验证、速率限制和请求修改。
插件 (Plugins): Traefik 可以通过插件进行扩展，从而增强其功能。插件系统允许开发人员贡献自定义插件。
这些组件的编排如下：
Traefik 摄取静态配置并开始监控指定的入口点。 提供商持续扫描基础设施以查找配置更改，并通过动态配置通道将其转发给 Traefik。 Traefik 处理动态配置，更新其内部结构——路由器、服务和中间件——以反映这些更改。 当请求进入时，Traefik 根据路由器规则对其进行匹配，并将其引导至指定的服务。 服务应用其负载均衡逻辑将请求分发到后端服务器。 中间件可以在请求/响应生命周期的各个阶段被调用，以执行其各自的职责。 这种动态架构使 Traefik 能够敏捷地适应基础设施内的变化，自动调整路由配置以与已部署的服务保持一致。
...</p></div><footer class=entry-footer><span title='2024-03-09 14:54:00 +0800 +0800'>2024年3月9日</span>&nbsp;·&nbsp;<span>zhoukuncheng</span></footer><a class=entry-link aria-label="post link to Traefik 架构与源码分析：深度探索" href=https://zhoukuncheng.github.io/zh/posts/traefik-architecture-and-source-code-analysis/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>流畅的实时数据流：像 ChatGPT 一样掌握 HTML5 SSE</h2></header><div class=entry-content><p>简介 在像 ChatGPT 这样的服务表现出色的实时交互时代，对于开发者来说，利用能够在应用程序中实现无缝数据流的技术至关重要。本文将深入探讨 HTML5 服务器发送事件 (Server-Sent Events, SSE) 的世界，这是一个类似于对话式 AI 接口背后的强大工具。就像 ChatGPT 通过流式传输数据来提供即时响应一样，SSE 使网络浏览器能够从服务器接收更新，而无需重复的客户端请求。无论你是构建聊天应用程序、实时通知系统，还是任何需要实时数据流的服务，本指南都将为你提供在应用程序中高效实施 SSE 的知识，确保响应迅速且引人入胜的用户体验。
理解服务器发送事件 (SSE) 服务器发送事件 (SSE) 是一种 Web 技术，它促进了服务器通过已建立的 HTTP 连接向客户端发送实时更新的能力。客户端可以通过 EventSource JavaScript API 接收连续的数据流或消息，该 API 包含在 WHATWG 的 HTML5 规范中。SSE 的官方媒体类型是 text/event-stream。
下面是一个典型 SSE 响应的说明性示例：
event:message data:The Current Time Is 2023-12-30 23:00:21 event:message data:The Current Time Is 2023-12-30 23:00:31 event:message data:The Current Time Is 2023-12-30 23:00:41 event:message data:The Current Time Is 2023-12-30 23:00:51 SSE 消息中的字段 通过 SSE 传输的消息可能包含以下字段：
...</p></div><footer class=entry-footer><span title='2023-12-30 23:11:34 +0800 +0800'>2023年12月30日</span>&nbsp;·&nbsp;<span>zhoukuncheng</span></footer><a class=entry-link aria-label="post link to 流畅的实时数据流：像 ChatGPT 一样掌握 HTML5 SSE" href=https://zhoukuncheng.github.io/zh/posts/html5-sse/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>如何成为开源项目的贡献者</h2></header><div class=entry-content><p>简介 基本流程 挑选项目 工作中接触 日常使用 熟悉项目使用的技术栈 …… 发现问题 代码 拼写 文档 测试 …… fork 修改 代码 测试 注释 文档 签署开源贡献协议 CLA DCO 提交 pull request CI review merge 后续 关闭 issue 等待 release 持续贡献，成为维护者 总体原则 如何成为合格的开源项目贡献者 确定你的技能和技术栈，选择与之匹配的开源项目 了解开源项目的代码结构、功能和规范，并阅读其贡献指南 各类贡献都可以，可以是修复 bug、添加功能、编写文档、测试等 从小的修改开始，比如修改文档、拼写，增加测试代码，修复影响范围较小 bug 核心流程：创建并提交 pull request (PR)，并等待其他贡献者的评审和反馈 与其他贡献者保持良好的沟通和协作 遵循开源项目的行为准则 非英语母语者如何更好地参与 提高英语水平，尤其是阅读和写作能力，这样才能更好地理解项目的需求、文档和代码，并能够清晰地表达想法和建议 选择一些有活跃社区和友好氛围的开源项目，这样可以得到更多的帮助和支持，也可以学习其他贡献者的经验和技巧 遵循开源项目的贡献流程，如 fork、clone、branch、commit、push 和 pull request 等，并遵守项目的编码风格和规范 在提交 issue 或 PR 时，尽量使用简单明了的英语描述问题或功能，并附上相关的截图或代码片段 在与其他贡献者沟通时，保持礼貌和尊重，不要害怕提问或回答问题，并及时回复他们的评审和反馈 如果对某些英语单词或表达不确定，可以使用在词典、翻译或语法检查工具进行辅助交流 如何让开源项目维护者迅速 review 自己的 PR 遵循项目指南：在提交 pull request 之前，请务必查看并遵循项目的贡献指南。确保请求符合项目的规范和标准。 确保代码风格一致：遵循项目的代码风格和格式要求，以减少维护者在 review 时需要修改的代码量。 提供详细描述：在提交 pull request 时，确保提供足够详细的描述，说明修改如何解决问题或改进项目。 提供测试用例：尽量保证新增的代码被覆盖到，有些项目会检测单测覆盖率和覆盖行。 及时回复评论：一旦您的 pull request 得到 review，尽可能快地回复维护者的评论，并考虑讨论的意见和建议。 GIthub Flow ...</p></div><footer class=entry-footer><span title='2023-11-26 01:11:34 +0800 +0800'>2023年11月26日</span>&nbsp;·&nbsp;<span>zhoukuncheng</span></footer><a class=entry-link aria-label="post link to 如何成为开源项目的贡献者" href=https://zhoukuncheng.github.io/zh/posts/opensource-contribution/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Structured concurrency</h2></header><div class=entry-content><p>简介 定义 根据维基百科的解释：
Structured concurrency is a programming paradigm aimed at improving the clarity, quality, and development time of a computer program by using a structured approach to concurrent programming.
The core concept is the encapsulation of concurrent threads of execution (here encompassing kernel and userland threads and processes) by way of control flow constructs that have clear entry and exit points and that ensure all spawned threads have completed before exit. Such encapsulation allows errors in concurrent threads to be propagated to the control structure’s parent scope and managed by the native error handling mechanisms of each particular computer language. It allows control flow to remain readily evident by the structure of the source code despite the presence of concurrency. To be effective, this model must be applied consistently throughout all levels of the program – otherwise concurrent threads may leak out, become orphaned, or fail to have runtime errors correctly propagated.
...</p></div><footer class=entry-footer><span title='2022-08-01 23:54:05 +0800 +0800'>2022年8月1日</span>&nbsp;·&nbsp;<span>zhoukuncheng</span></footer><a class=entry-link aria-label="post link to Structured concurrency" href=https://zhoukuncheng.github.io/zh/posts/structured-concurrency/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Go 1.18 泛型介绍</h2></header><div class=entry-content><p>什么是泛型 泛型程序设计（generic programming）是程序设计语言的一种风格或范式。泛型允许程序员在编写代码时使用一些以后才指定的类型，在实例化时作为参数指明这些类型。
Golang 泛型基本用法 示例 map 操作
package main import ( "fmt" ) func mapFunc[T any, M any](a []T, f func(T) M) []M { n := make([]M, len(a), cap(a)) for i, e := range a { n[i] = f(e) } return n } func main() { vi := []int{1, 2, 3, 4, 5, 6} vs := mapFunc(vi, func(v int) string { return "&lt;" + fmt.Sprint(v * v) + ">" }) fmt.Println(vs) } min max 函数
...</p></div><footer class=entry-footer><span title='2022-03-16 22:41:56 +0800 +0800'>2022年3月16日</span>&nbsp;·&nbsp;<span>zhoukuncheng</span></footer><a class=entry-link aria-label="post link to Go 1.18 泛型介绍" href=https://zhoukuncheng.github.io/zh/posts/go-generics/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>通过 gRPC-Gateway 开发 RESTful API</h2></header><div class=entry-content><p>gRPC-Gateway 简介 gRPC-Gateway 是 protoc 的一个插件，工作机制是读取一个 gRPC 服务定义并生成一个反向代理服务器，将 RESTful JSON API 翻译成 gRPC。
这个服务器是根据编写的 gRPC 定义中的自定义选项来生成的。
安装使用 依赖工具 工具 简介 安装 protobuf protocol buffer 编译所需的命令行 http://google.github.io/proto-lens/installing-protoc.html protoc-gen-go 从 proto 文件，生成 .go 文件 https://grpc.io/docs/languages/go/quickstart/ protoc-gen-go-grpc 从 proto 文件，生成 gRPC 相关的 .go 文件 https://grpc.io/docs/languages/go/quickstart/ protoc-gen-grpc-gateway 从 proto 文件，生成 gRPC-gateway 相关的 .go 文件 https://github.com/grpc-ecosystem/grpc-gateway#installation protoc-gen-openapiv2 从 proto 文件，生成 swagger 文档所需的参数文件 https://github.com/grpc-ecosystem/grpc-gateway#installation buf protobuf 管理工具，可选，简化命令行操作和protobuf 文件管理 https://docs.buf.build/installation 步骤 编写buf配置 buf.gen.yaml
version: v1beta1 plugins: - name: go out: internal/proto opt: - paths=source_relative - name: go-grpc out: internal/proto opt: - paths=source_relative - require_unimplemented_servers=false - name: grpc-gateway out: internal/proto opt: - paths=source_relative - name: openapiv2 out: openapi opt: - json_names_for_fields=false buf.yaml
...</p></div><footer class=entry-footer><span title='2022-03-13 18:13:14 +0800 +0800'>2022年3月13日</span>&nbsp;·&nbsp;<span>zhoukuncheng</span></footer><a class=entry-link aria-label="post link to 通过 gRPC-Gateway 开发 RESTful API" href=https://zhoukuncheng.github.io/zh/posts/go-grpc-gateway/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Python 与 Go 之间的并发模式差异</h2></header><div class=entry-content><p>Python并发方式 在 Python 中，早期并发方式以传统的多进程和多线程为主，类似 Java，同时，有不少第三方的异步方案（gevent/tornado/twisted 等）。
在 Python 3 时期，官方推出了 asyncio 和 async await 语法，作为 Python 官方的协程实现，而逐渐普及。
进程 多进程编程示例：
from multiprocessing import Process def f(name): print('hello', name) if __name__ == '__main__': p = Process(target=f, args=('bob',)) p.start() p.join() multiprocessing 与 threading 的 API 接近，比较容易创建多进程的程序，是 Python 官方推荐作为绕过多线程 GIL 限制的一种方案。
但需要注意，创建进程的参数需要能被 pickle 序列化，最好使用 Pipe、Queue 等进程安全的数据结构（官方文档的 Programming guidelines）
线程 多线程代码示例：
from threading import Thread def f(name): print('hello', name) if __name__ == '__main__': p = Thread(target=f, args=('bob',)) p.start() p.join() # 线程池方式 with ThreadPoolExecutor(max_workers=1) as executor: future = executor.submit(pow, 323, 1235) print(future.result()) Cpython 线程的缺陷：GIL（全局解释器锁）
GIL 是 Cpython 执行 Python 字节码时的一把全局锁，导致解释器在 CPU 密集型任务时不能充分利用多核，而 IO 密集型任务会释放 GIL。 如果想绕过 GIL，只能换成多进程方式，或者通过C 扩展绕过。
...</p></div><footer class=entry-footer><span title='2021-08-30 23:54:05 +0800 +0800'>2021年8月30日</span>&nbsp;·&nbsp;<span>zhoukuncheng</span></footer><a class=entry-link aria-label="post link to Python 与 Go 之间的并发模式差异" href=https://zhoukuncheng.github.io/zh/posts/concurrency-model-differences-between-python-go/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Distributed Systems for Fun and Profit 笔记（二）</h2></header><div class=entry-content><p>2. 抽象的上下不同层次 系统模型 分布式系统中的程序：
在独立节点上同时运行
通过可能引入不确定性和消息丢失的网络连接
并且没有共享内存或共享时钟
系统模型列举了与特定系统设计相关的许多假设，实现分布式系统的环境和设施的假设：
节点具有什么功能以及它们如何失败 通信连接如何运行以及它们如何可能失败 整个系统的属性，例如关于时间和顺序的假设 健壮的系统模型做出最弱假设，强有力的假设创建易于推理的系统模型
此模型中的节点 作为计算和存储的主机：
执行程序的能力 能够将数据存储到内存和稳定持久状态的能力 时钟 节点执行确定性算法
故障模型：崩溃恢复而非拜占庭容错（任意错误）
此模型中的通信连接 通信连接将各个节点相互连接，并任一方向发送消息
网络不可靠，消息易延迟丢失
网络分区：网络断开但节点存活
时间和顺序的假设 信息最多以光速传播
如果距离不同，节点间消息的到达时间、顺序可能不同
同步系统模型 进程以锁定步骤执行；消息传输延迟有已知上限；每个进程都有准确的时钟
异步系统模型 没有时间假设，进程以独立的速率执行；消息传输延迟没有限制；有用的时钟不存在
共识问题 多个节点都同意一些值时达成共识
一致：每个正确节点都同意相同的值
完整：每个正确的进程最多只能决定一个值，如果决定某个值，那么一定是某些进程提议的
终止：所有进程最终达成决定
有效：如果所有正确进程提议相同的值 V，那么所有正确进程决定值 V
两种不可能的结果 FLP 不可能 假定节点只能因崩溃而失效；网络可靠，并且异步系统模型的典型时序假设成立：例如，消息延迟没有限制，
在网络可靠，但允许节点失效（即便只有一个）的最小化异步模型系统中，不存在一个可以解决一致性问题的确定性共识算法
CAP 定理 三个属性：
（强）一致性：所有节点同时看到相同的数据
可用性：节点故障不会阻止幸存者继续运行
分区容错：网络或节点故障导致消息丢失时，系统仍可继续运行
同时具备这三种属性的系统无法实现：
三种不同的系统类型：
CA（一致性+可用性）：完全严格的仲裁协议，例如两阶段提交 CP（一致性+分区容错）：多数仲裁协议，其中少数分区不可用，例如Paxos AP（可用性+分区容错）：使用冲突解决方案的协议，例如Dynamo 一致性模型：程序员与系统之间的合同，其中系统保证，如果程序员遵循某些特定规则，则对数据存储区的操作结果将是可预测的
强一致性模型（能够维护单个副本） Linearizable consistency （可线性化一致性） Sequential consistency （顺序一致性） 弱一致性 Client-centric consistency models （客户端为中心一致性） Causal consistency: strongest model available （因果一致性） Eventual consistency models （最终一致性） 线性化一致性要求操作生效的顺序等于操作的实际实时顺序，顺序一致性允许对操作进行重新排序，只要在每个节点上观察到的顺序保持一致</p></div><footer class=entry-footer><span title='2020-09-15 09:22:15 +0800 +0800'>2020年9月15日</span>&nbsp;·&nbsp;<span>zhoukuncheng</span></footer><a class=entry-link aria-label="post link to Distributed Systems for Fun and Profit 笔记（二）" href=https://zhoukuncheng.github.io/zh/posts/distributed-systems-for-fun-and-profit-part2/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Distributed Systems for Fun and Profit 笔记 （一）</h2></header><div class=entry-content><p>0. 前言 “Distributed Systems for Fun and Profit” 是 mixu 2013 年在 网络上 免费发布的一本介绍分布式系统的小册子。
分布式的两种结果：
信息以光速传播 独立节点独自失败 分布式系统处理距离和多个节点的问题
1. 从高层次角度看分布式系统 计算机的基本任务
存储
计算
分布式编程就是用多机解决在单机上的相同问题，通常此问题单机已经不能满足要求。
小规模时，单个节点上升级硬件可以解决问题，但随着问题规模增大，单节点升级硬件无法解决或者成本过高时就需要分布式系统。当前最值得的是中档的商业硬件，通过容错软件降低成本。
增加新机器不会像理想情况一样线性增加性能和容量。
本文重点是讨论数据中心上的分布式编程。
实现目标：可扩展性等优点 可扩展性 可扩展性（Scalability）：系统、网络或进程有能力处理不断增长的工作量的能力，或者为了适应这种增长而进行扩展的能力
大小可扩展 地理可扩展 管理可扩展 性能与延迟 性能（Performance）：参照资源和时间，系统完成的有效工作量
延迟（Latency）：重要是的新数据在系统中出现的时间，分布式系统中受制于光速和硬盘速度等
可用性（容错） 可用性（Availability）：系统处于正常运行状态的时间比例， Availability = uptime / (uptime + downtime)
分布式系统可以通过冗余实现容忍部分故障
容错（Fault tolerance）：故障发生后系统以明确定义的方式运行的能力
制约 分布式系统受两个物理因素的约束：
节点数（随所需的存储和计算能力而增加） 节点之间的距离（信息最多以光速传播） 性能和可用性由外部定义，通常表述为SLA（服务级别协议）
抽象和模型 抽象使事情变得更易于管理，模型精确描述分布式系统的关键特性。
如：
系统模型（异步/同步）
失败模型（崩溃失败，分区，拜占庭）
一致性模型（强一致，最终一致）
设计技巧：分区和复制 分区（Partition） 将大数据集划分为小的独立集
分区通过限制要检查的数据量并在同一分区中定位相关数据来提高性能 分区通过允许分区独立发生故障来提高可用性 复制（Replication） 在多机上复制相同的数据，是对抗延迟的主要办法
通过增加新数据副本上的计算能力和带宽来提高性能 通过创建数据的其他副本来提高可用性 复制需要遵循一致性模型</p></div><footer class=entry-footer><span title='2020-09-11 01:51:32 +0800 +0800'>2020年9月11日</span>&nbsp;·&nbsp;<span>zhoukuncheng</span></footer><a class=entry-link aria-label="post link to Distributed Systems for Fun and Profit 笔记 （一）" href=https://zhoukuncheng.github.io/zh/posts/distributed-systems-for-fun-and-profit-part1/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>编译 CPython 心得</h2></header><div class=entry-content><p>什么情况下需要自己编译 CPython 大多数操作系统都提供了编译好的 CPython 版本，一般直接通过包管理器安装就能满足需求，但是某些情况下，就需要自己编译 CPython 来满足特定需求了：
操作系统提供的 Python 版本太低，并且 Python 官网、系统包管理源没有提供预编译的新版本 Python
预编译版本不符合性能、扩展等方面的要求，比如没有开启编译器优化、OpenSSL/SQLite 版本不满足要求等
参与 CPython 开发或者尝鲜，尝试 Alpha/Beta/RC 等版本的 Python
​ ​
低版本 Linux 发行版上编译 CPython 时的注意事项 OpenSSL 因为 CentOS 6 官方源中的 OpenSSL 版本过低，不满足 Python 3.7 及之后的要求，所以直接 configure & make 会报错，解决办法：
参考 Python 3.7 on CentOS 6 , 提前编译 OpenSSL, 编译 CPython 时修改 Modules/Setup 文件，并且指定环境变量 LDFLAGS="-Wl,-rpath=/usr/local/openssl11/lib" , 指定参数 -with-openssl=/usr/local/openssl11 。
SQLite Jupyter 等软件依赖 SQLite, 所以编译 CPython 时不仅要注意 SQLite 版本，也要开启 --enable-loadable-sqlite-extensions , 参考：How to use enable_load_extension from sqlite3?
...</p></div><footer class=entry-footer><span title='2020-07-24 01:11:34 +0800 +0800'>2020年7月24日</span>&nbsp;·&nbsp;<span>zhoukuncheng</span></footer><a class=entry-link aria-label="post link to 编译  CPython 心得 " href=https://zhoukuncheng.github.io/zh/posts/python-build/></a></article></main><footer class=footer><span>&copy; 2026 <a href=https://zhoukuncheng.github.io/zh/>zhoukuncheng's Personal Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script></body></html>