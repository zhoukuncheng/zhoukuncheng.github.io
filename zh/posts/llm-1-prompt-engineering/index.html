<!doctype html><html lang=zh dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>LLM 学习系列 1：提示工程 | zhoukuncheng's Personal Blog</title><meta name=keywords content="LLM,Prompt Engineering"><meta name=description content='掌握 LLM 提示词的艺术
像 GPT-4 和 Claude 这样的大型语言模型 (LLM) 拥有非凡的能力。然而，要释放它们的全部潜力，需要通过精心设计的提示词 (prompts) 进行有效沟通。本指南深入探讨了提示工程 (prompt engineering) 的艺术，提供了一个从基本原则到高级技巧的分步方法，以驾驭 LLM 的真正力量。
第一步：选择最佳模型


最新且最强： 像 GPT-4 Turbo 这样的较新模型相比 GPT-3.5 Turbo 等前代产品提供了显著优势，包括更流畅的自然语言理解能力。对于较简单的任务，通过大量的提示工程来弥补模型能力的必要性可能会降低。


基准测试： 利用 LLM 排行榜 和基准测试结果等资源来比较模型，并找出最适合你特定需求的模型。



示例：

对于细致入微的语言翻译，GPT-4 Turbo 的上下文理解能力可能优于旧模型。
对于既需要能力又需要速度的任务，Llama-3-70b 开源模型是一个绝佳的选择。

第二步：建立清晰的沟通
清晰度和具体性


明确的指令： 将 LLM 视为通过需要清晰指导的合作者。明确定义任务、期望的结果、格式、风格和输出长度，避免歧义。


上下文背景： 提供相关的背景信息和语境，以引导 LLM 做出期望的回应，同时考虑目标受众和目的。


关注点分离： 使用 ### 或 """ 将指令与上下文内容清晰地分隔开。


以示例为向导： 用精选的示例来演示期望的输出格式和风格。


线索提示： 使用短语如 &ldquo;Key points:"（关键点：）、&ldquo;Summary:"（摘要：）或 &ldquo;Code:"（代码：）来指示期望的输出格式。


示例：

不要只说 &ldquo;写一篇博客文章&rdquo;，而应指定 &ldquo;写一篇关于可再生能源影响的 500 字博客文章，目标受众是行业专业人士。&rdquo;
对于诗歌生成任务，你可以指定期望的基调、韵律和主题。

少样本学习 (Few-Shot Learning)
提供几个展示了期望输出格式和风格的示例，以减少歧义并设定清晰的预期。'><meta name=author content="zhoukuncheng"><link rel=canonical href=https://zhoukuncheng.github.io/zh/posts/llm-1-prompt-engineering/><link crossorigin=anonymous href=/assets/css/stylesheet.343cc480b9ffc8f04ccbe5e968ad674880cab773ec19905e93033065c1e7a804.css integrity="sha256-NDzEgLn/yPBMy+XpaK1nSIDKt3PsGZBekwMwZcHnqAQ=" rel="preload stylesheet" as=style><link rel=icon href=https://zhoukuncheng.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://zhoukuncheng.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://zhoukuncheng.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://zhoukuncheng.github.io/apple-touch-icon.png><link rel=mask-icon href=https://zhoukuncheng.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=https://zhoukuncheng.github.io/zh/posts/llm-1-prompt-engineering/><link rel=alternate hreflang=en href=https://zhoukuncheng.github.io/posts/llm-1-prompt-engineering/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-GH88YSLNJN"></script><script>var doNotTrack=!1,dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-GH88YSLNJN")}</script><meta property="og:url" content="https://zhoukuncheng.github.io/zh/posts/llm-1-prompt-engineering/"><meta property="og:site_name" content="zhoukuncheng's Personal Blog"><meta property="og:title" content="LLM 学习系列 1：提示工程"><meta property="og:description" content='掌握 LLM 提示词的艺术 像 GPT-4 和 Claude 这样的大型语言模型 (LLM) 拥有非凡的能力。然而，要释放它们的全部潜力，需要通过精心设计的提示词 (prompts) 进行有效沟通。本指南深入探讨了提示工程 (prompt engineering) 的艺术，提供了一个从基本原则到高级技巧的分步方法，以驾驭 LLM 的真正力量。
第一步：选择最佳模型 最新且最强： 像 GPT-4 Turbo 这样的较新模型相比 GPT-3.5 Turbo 等前代产品提供了显著优势，包括更流畅的自然语言理解能力。对于较简单的任务，通过大量的提示工程来弥补模型能力的必要性可能会降低。
基准测试： 利用 LLM 排行榜 和基准测试结果等资源来比较模型，并找出最适合你特定需求的模型。
示例：
对于细致入微的语言翻译，GPT-4 Turbo 的上下文理解能力可能优于旧模型。 对于既需要能力又需要速度的任务，Llama-3-70b 开源模型是一个绝佳的选择。 第二步：建立清晰的沟通 清晰度和具体性 明确的指令： 将 LLM 视为通过需要清晰指导的合作者。明确定义任务、期望的结果、格式、风格和输出长度，避免歧义。
上下文背景： 提供相关的背景信息和语境，以引导 LLM 做出期望的回应，同时考虑目标受众和目的。
关注点分离： 使用 ### 或 """ 将指令与上下文内容清晰地分隔开。
以示例为向导： 用精选的示例来演示期望的输出格式和风格。
线索提示： 使用短语如 “Key points:"（关键点：）、“Summary:"（摘要：）或 “Code:"（代码：）来指示期望的输出格式。
示例：
不要只说 “写一篇博客文章”，而应指定 “写一篇关于可再生能源影响的 500 字博客文章，目标受众是行业专业人士。” 对于诗歌生成任务，你可以指定期望的基调、韵律和主题。 少样本学习 (Few-Shot Learning) 提供几个展示了期望输出格式和风格的示例，以减少歧义并设定清晰的预期。'><meta property="og:locale" content="zh-CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-04-27T11:11:34+08:00"><meta property="article:modified_time" content="2024-04-27T11:11:34+08:00"><meta property="article:tag" content="LLM"><meta property="article:tag" content="Prompt Engineering"><meta name=twitter:card content="summary"><meta name=twitter:title content="LLM 学习系列 1：提示工程"><meta name=twitter:description content='掌握 LLM 提示词的艺术
像 GPT-4 和 Claude 这样的大型语言模型 (LLM) 拥有非凡的能力。然而，要释放它们的全部潜力，需要通过精心设计的提示词 (prompts) 进行有效沟通。本指南深入探讨了提示工程 (prompt engineering) 的艺术，提供了一个从基本原则到高级技巧的分步方法，以驾驭 LLM 的真正力量。
第一步：选择最佳模型


最新且最强： 像 GPT-4 Turbo 这样的较新模型相比 GPT-3.5 Turbo 等前代产品提供了显著优势，包括更流畅的自然语言理解能力。对于较简单的任务，通过大量的提示工程来弥补模型能力的必要性可能会降低。


基准测试： 利用 LLM 排行榜 和基准测试结果等资源来比较模型，并找出最适合你特定需求的模型。



示例：

对于细致入微的语言翻译，GPT-4 Turbo 的上下文理解能力可能优于旧模型。
对于既需要能力又需要速度的任务，Llama-3-70b 开源模型是一个绝佳的选择。

第二步：建立清晰的沟通
清晰度和具体性


明确的指令： 将 LLM 视为通过需要清晰指导的合作者。明确定义任务、期望的结果、格式、风格和输出长度，避免歧义。


上下文背景： 提供相关的背景信息和语境，以引导 LLM 做出期望的回应，同时考虑目标受众和目的。


关注点分离： 使用 ### 或 """ 将指令与上下文内容清晰地分隔开。


以示例为向导： 用精选的示例来演示期望的输出格式和风格。


线索提示： 使用短语如 &ldquo;Key points:"（关键点：）、&ldquo;Summary:"（摘要：）或 &ldquo;Code:"（代码：）来指示期望的输出格式。


示例：

不要只说 &ldquo;写一篇博客文章&rdquo;，而应指定 &ldquo;写一篇关于可再生能源影响的 500 字博客文章，目标受众是行业专业人士。&rdquo;
对于诗歌生成任务，你可以指定期望的基调、韵律和主题。

少样本学习 (Few-Shot Learning)
提供几个展示了期望输出格式和风格的示例，以减少歧义并设定清晰的预期。'><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://zhoukuncheng.github.io/zh/posts/"},{"@type":"ListItem","position":2,"name":"LLM 学习系列 1：提示工程","item":"https://zhoukuncheng.github.io/zh/posts/llm-1-prompt-engineering/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"LLM 学习系列 1：提示工程","name":"LLM 学习系列 1：提示工程","description":"掌握 LLM 提示词的艺术 像 GPT-4 和 Claude 这样的大型语言模型 (LLM) 拥有非凡的能力。然而，要释放它们的全部潜力，需要通过精心设计的提示词 (prompts) 进行有效沟通。本指南深入探讨了提示工程 (prompt engineering) 的艺术，提供了一个从基本原则到高级技巧的分步方法，以驾驭 LLM 的真正力量。\n第一步：选择最佳模型 最新且最强： 像 GPT-4 Turbo 这样的较新模型相比 GPT-3.5 Turbo 等前代产品提供了显著优势，包括更流畅的自然语言理解能力。对于较简单的任务，通过大量的提示工程来弥补模型能力的必要性可能会降低。\n基准测试： 利用 LLM 排行榜 和基准测试结果等资源来比较模型，并找出最适合你特定需求的模型。\n示例：\n对于细致入微的语言翻译，GPT-4 Turbo 的上下文理解能力可能优于旧模型。 对于既需要能力又需要速度的任务，Llama-3-70b 开源模型是一个绝佳的选择。 第二步：建立清晰的沟通 清晰度和具体性 明确的指令： 将 LLM 视为通过需要清晰指导的合作者。明确定义任务、期望的结果、格式、风格和输出长度，避免歧义。\n上下文背景： 提供相关的背景信息和语境，以引导 LLM 做出期望的回应，同时考虑目标受众和目的。\n关注点分离： 使用 ### 或 \u0026quot;\u0026quot;\u0026quot; 将指令与上下文内容清晰地分隔开。\n以示例为向导： 用精选的示例来演示期望的输出格式和风格。\n线索提示： 使用短语如 \u0026ldquo;Key points:\u0026quot;（关键点：）、\u0026ldquo;Summary:\u0026quot;（摘要：）或 \u0026ldquo;Code:\u0026quot;（代码：）来指示期望的输出格式。\n示例：\n不要只说 \u0026ldquo;写一篇博客文章\u0026rdquo;，而应指定 \u0026ldquo;写一篇关于可再生能源影响的 500 字博客文章，目标受众是行业专业人士。\u0026rdquo; 对于诗歌生成任务，你可以指定期望的基调、韵律和主题。 少样本学习 (Few-Shot Learning) 提供几个展示了期望输出格式和风格的示例，以减少歧义并设定清晰的预期。\n","keywords":["LLM","Prompt Engineering"],"articleBody":"掌握 LLM 提示词的艺术 像 GPT-4 和 Claude 这样的大型语言模型 (LLM) 拥有非凡的能力。然而，要释放它们的全部潜力，需要通过精心设计的提示词 (prompts) 进行有效沟通。本指南深入探讨了提示工程 (prompt engineering) 的艺术，提供了一个从基本原则到高级技巧的分步方法，以驾驭 LLM 的真正力量。\n第一步：选择最佳模型 最新且最强： 像 GPT-4 Turbo 这样的较新模型相比 GPT-3.5 Turbo 等前代产品提供了显著优势，包括更流畅的自然语言理解能力。对于较简单的任务，通过大量的提示工程来弥补模型能力的必要性可能会降低。\n基准测试： 利用 LLM 排行榜 和基准测试结果等资源来比较模型，并找出最适合你特定需求的模型。\n示例：\n对于细致入微的语言翻译，GPT-4 Turbo 的上下文理解能力可能优于旧模型。 对于既需要能力又需要速度的任务，Llama-3-70b 开源模型是一个绝佳的选择。 第二步：建立清晰的沟通 清晰度和具体性 明确的指令： 将 LLM 视为通过需要清晰指导的合作者。明确定义任务、期望的结果、格式、风格和输出长度，避免歧义。\n上下文背景： 提供相关的背景信息和语境，以引导 LLM 做出期望的回应，同时考虑目标受众和目的。\n关注点分离： 使用 ### 或 \"\"\" 将指令与上下文内容清晰地分隔开。\n以示例为向导： 用精选的示例来演示期望的输出格式和风格。\n线索提示： 使用短语如 “Key points:\"（关键点：）、“Summary:\"（摘要：）或 “Code:\"（代码：）来指示期望的输出格式。\n示例：\n不要只说 “写一篇博客文章”，而应指定 “写一篇关于可再生能源影响的 500 字博客文章，目标受众是行业专业人士。” 对于诗歌生成任务，你可以指定期望的基调、韵律和主题。 少样本学习 (Few-Shot Learning) 提供几个展示了期望输出格式和风格的示例，以减少歧义并设定清晰的预期。\n示例：\n提示： 将这些句子翻译成西班牙语：\n“The cat sat on the mat.” - “El gato se sentó en la alfombra.” “The dog barked at the mailman.” - “El perro ladró al cartero.” “The children played in the park.” 期望输出： “Los niños jugaron en el parque.”\n提示： 以风趣迷人的风格撰写产品描述：\n产品： 降噪耳机 描述： “带上这款降噪耳机，让世界静音，迷失在你自己的声景中。这是逃离日常琐事或专注于工作的完美之选。” 产品： 旅行背包 描述： “这款旅行背包是你终极的冒险伴侣。凭借其宽敞的隔层和耐用的设计，它已准备好与你一起探索世界。” 产品： 智能手表 描述： 期望输出： “这就不仅仅是一块计时的表；它是你的私人助理、健身追踪器和通知中心，所有这些都包裹在一个时尚的设计中。”\n第三步：引导 LLM 的思维过程 思维链 (Chain-of-Thought, CoT) 提示 对于复杂的推理任务，引导 LLM 一步步地完成思维过程，鼓励它分解问题并生成导致答案的逻辑推理步骤序列。\n示例：\n问题： 约翰有 5 个苹果，给了玛丽 2 个，然后又买了 5 个。他现在有多少个苹果？\nCoT 提示： “约翰开始有 5 个苹果。给了玛丽 2 个后，他还剩 3 个。又买了 5 个，让他有 3 + 5 = 8 个苹果。”\n问题： 谁是 2000 年悉尼奥运会上获得奖牌最多的个人运动员？要在你的回答中采取循序渐进的方法，在分享以下格式的最终答案之前引用来源并给出推理：答案是：\u003c名字\u003e\nCoT 提示：\n步骤 1：确定悉尼奥运会的年份。悉尼奥运会于 2000 年举行。 步骤 2：查找在 2000 年悉尼奥运会上获得多枚奖牌的个人运动员名单。 根据奥运会官方网站，有几位个人运动员在 2000 年悉尼奥运会上赢得了多枚奖牌。一些著名的名字包括： • 伊恩·索普 (Ian Thorpe) (澳大利亚) - 3 金, 2 银, 0 铜 • 彼得·范·登·霍根班德 (Pieter van den Hoogenband) (荷兰) - 2 金, 0 银, 2 铜 • 伦尼·克雷泽尔堡 (Lenny Krayzelburg) (美国) - 3 金, 0 银, 0 铜 • 英格·德·布鲁因 (Inge de Bruijn) (荷兰) - 3 金, 1 银, 0 铜 步骤 3：确定奖牌最多的运动员。查看了 2000 年悉尼奥运会上获得多枚奖牌的个人运动员名单后，我们可以看到奖牌最多的运动员是来自澳大利亚的伊恩·索普，他总共获得了 5 枚奖牌（3 金和 2 银）。 因此，答案是：伊恩·索普。 自我一致性 (Self-Consistency) 生成多个输出并选择最一致或最频繁的响应，以减轻偏差并提高可靠性。\n示例：\n当寻求历史事实时，生成多个解释并根据共识选择最频繁或看似准确的一个。 同样，对于像故事生成这样的创造性任务，生成多个草稿并选择最引人入胜或连贯的叙述可能是有益的。 提示：\n问：小树林里有 15 棵树。果园工人今天将在小树林里种树。等他们做完后， 将会有 21 棵树。果园工人今天种了多少棵树？ 答：我们从 15 棵树开始。后来我们有 21 棵树。差值必定是他们种植的树的数量。 所以，他们一定种了 21 - 15 = 6 棵树。答案是 6。 问：如果停车场有 3 辆车，又来了 2 辆车，停车场里有多少辆车？ 答：停车场里已经有 3 辆车了。又来了 2 辆。现在有 3 + 2 = 5 辆车。答案是 5。 问：利亚有 32 块巧克力，她姐姐有 42 块。如果她们吃了 35 块，她们总共还剩多少块？ 答：利亚有 32 块巧克力，利亚的姐姐有 42 块。这意味着最初有 32 + 42 = 74 块巧克力。已经吃了 35 块。所以她们总共还有 74 - 35 = 39 块巧克力。答案是 39。 问：杰森有 20 根棒棒糖。他给了丹尼一些棒棒糖。现在杰森有 12 根棒棒糖。杰森给了丹尼多少根棒棒糖？ 答：杰森有 20 根棒棒糖。因为他现在只有 12 根，他一定把剩下的给了丹尼。他给丹尼的棒棒糖数量一定是 20 - 12 = 8 根。答案是 8。 问：肖恩有五个玩具。圣诞节时，他从父母那里各得到了两个玩具。他现在有多少个玩具？ 答：他有 5 个玩具。他从妈妈那里得到了 2 个，所以之后他有 5 + 2 = 7 个玩具。然后他又从爸爸那里得到了 2 个，所以总共他有 7 + 2 = 9 个玩具。答案是 9。 问：服务器机房有九台电脑。从周一到周四，每天安装五台以上的电脑。现在服务器机房有多少台电脑？ 答：从周一到周四有 4 天。每天增加 5 台电脑。这意味着总共增加了 4 * 5 = 20 台电脑。开始时有 9 台电脑，所以现在有 9 + 20 = 29 台电脑。 答案是 29。 问：迈克尔有 58 个高尔夫球。周二，他丢了 23 个高尔夫球。周三，他又丢了 2 个。周三结束时他有多少个高尔夫球？ 答：迈克尔最初有 58 个球。他在周二丢了 23 个，所以之后他有 58 - 23 = 35 个球。周三他又丢了 2 个，所以现在他有 35 - 2 = 33 个球。答案是 33。 问：奥利维亚有 23 美元。她买了五个百吉饼，每个 3 美元。她还剩多少钱？ 答：她买了 5 个百吉饼，每个 3 美元。这意味着她花了 15 美元。她还剩 8 美元。 问：我 6 岁时，我妹妹是我年龄的一半。现在我 70 岁了，我妹妹多大？ 答： 输出 1：\n我 6 岁时，我妹妹是我年龄的一半，所以她是 3 岁。现在我 70 岁了，所以她是 70 - 3 = 67 岁。答案是 67。 输出 2：\n当叙述者 6 岁时，他的妹妹是他年龄的一半，也就是 3 岁。现在叙述者 70 岁了，他的妹妹应该是 70 - 3 = 67 岁。答案是 67。 输出 3：\n我 6 岁时，我妹妹是我年龄的一半，所以她是 3 岁。现在我 70 岁了，所以她是 70/2 = 35 岁。答案是 35。 任务分解 使用提示链 (prompt chaining) 等技术将复杂的任务分解为更小、更易于管理的子任务。\n示例：\n要解决一个复杂的数学问题，首先让 LLM 识别问题类型，然后逐步解决每个部分，最后组合各部分得出解决方案。\n代码生成的提示链：\n提示 1： “编写一个 Python 函数，该函数接收一个数字列表作为输入。” 提示 2（基于提示 1 的输出）： “修改该函数以计算列表中所有数字的总和。” 提示 3（基于提示 2 的输出）： “向该函数添加功能，以返回列表中数字的平均值。” 第四步：增强能力和控制 系统提示 (System Prompt) 和角色 系统提示： 定义 LLM 的行为、角色、个性和限制。\n角色分配： 分配特定角色以聚焦回答并定制语言风格。\n示例：\n“你是一位友好的营养师，正在为一位麸质过敏的人提供均衡的饮食计划。” “你是一位经验丰富的旅行向导，正在创建一个为期一周的探索罗马历史古迹的行程。” 检索增强 (RAG) RAG： 将 LLM 与外部知识源（如数据库或 API）结合，以提高准确性和获取最新信息。 示例：\n“使用来自 XYZ API 的当前股市数据，分析并预测下周科技股的趋势。” “从科学数据库访问有关气候变化的最新研究论文，并总结主要发现和提出的解决方案。” 温度 (Temperature) 和 Top_p Temperature： 控制输出的随机性和创造性。\nTop_p： 调整下一个 token 的概率分布，以影响生成文本的多样性。\n示例：\n对于创意写作，较高的温度鼓励更多样化和意想不到的情节转折。对于事实报告，较低的温度确保信息更加直接和一致。 对于生成不同的创意文本格式，如诗歌、剧本或乐曲，调整温度和 top_p 可以导致所选格式内的风格和结构多样化。 参考资料 https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering\nhttps://platform.openai.com/docs/guides/prompt-engineering\nhttps://docs.anthropic.com/claude/docs/prompt-engineering\nhttps://www.promptingguide.ai/\n","wordCount":"537","inLanguage":"zh","datePublished":"2024-04-27T11:11:34+08:00","dateModified":"2024-04-27T11:11:34+08:00","author":{"@type":"Person","name":"zhoukuncheng"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://zhoukuncheng.github.io/zh/posts/llm-1-prompt-engineering/"},"publisher":{"@type":"Organization","name":"zhoukuncheng's Personal Blog","logo":{"@type":"ImageObject","url":"https://zhoukuncheng.github.io/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://zhoukuncheng.github.io/zh/ accesskey=h title="zhoukuncheng's Personal Blog (Alt + H)">zhoukuncheng's Personal Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://zhoukuncheng.github.io/ title=English aria-label=English>En</a></li></ul></div></div><ul id=menu><li><a href=https://zhoukuncheng.github.io/zh/ title=首页><span>首页</span></a></li><li><a href=https://zhoukuncheng.github.io/zh/posts/ title=归档><span>归档</span></a></li><li><a href=https://zhoukuncheng.github.io/zh/tags/ title=标签><span>标签</span></a></li><li><a href=https://zhoukuncheng.github.io/zh/categories/ title=分类><span>分类</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">LLM 学习系列 1：提示工程</h1><div class=post-meta><span title='2024-04-27 11:11:34 +0800 +0800'>2024年4月27日</span>&nbsp;·&nbsp;<span>zhoukuncheng</span>&nbsp;|&nbsp;<span>语言:</span><ul class=i18n_list><li><a href=https://zhoukuncheng.github.io/posts/llm-1-prompt-engineering/>En</a></li></ul></div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>目录</span></summary><div class=inner><ul><li><a href=#%e6%8e%8c%e6%8f%a1-llm-%e6%8f%90%e7%a4%ba%e8%af%8d%e7%9a%84%e8%89%ba%e6%9c%af aria-label="掌握 LLM 提示词的艺术">掌握 LLM 提示词的艺术</a><ul><li><a href=#%e7%ac%ac%e4%b8%80%e6%ad%a5%e9%80%89%e6%8b%a9%e6%9c%80%e4%bd%b3%e6%a8%a1%e5%9e%8b aria-label=第一步：选择最佳模型>第一步：选择最佳模型</a></li><li><a href=#%e7%ac%ac%e4%ba%8c%e6%ad%a5%e5%bb%ba%e7%ab%8b%e6%b8%85%e6%99%b0%e7%9a%84%e6%b2%9f%e9%80%9a aria-label=第二步：建立清晰的沟通>第二步：建立清晰的沟通</a><ul><li><a href=#%e6%b8%85%e6%99%b0%e5%ba%a6%e5%92%8c%e5%85%b7%e4%bd%93%e6%80%a7 aria-label=清晰度和具体性>清晰度和具体性</a></li><li><a href=#%e5%b0%91%e6%a0%b7%e6%9c%ac%e5%ad%a6%e4%b9%a0-few-shot-learning aria-label="少样本学习 (Few-Shot Learning)">少样本学习 (Few-Shot Learning)</a></li></ul></li><li><a href=#%e7%ac%ac%e4%b8%89%e6%ad%a5%e5%bc%95%e5%af%bc-llm-%e7%9a%84%e6%80%9d%e7%bb%b4%e8%bf%87%e7%a8%8b aria-label="第三步：引导 LLM 的思维过程">第三步：引导 LLM 的思维过程</a><ul><li><a href=#%e6%80%9d%e7%bb%b4%e9%93%be-chain-of-thought-cot-%e6%8f%90%e7%a4%ba aria-label="思维链 (Chain-of-Thought, CoT) 提示">思维链 (Chain-of-Thought, CoT) 提示</a></li><li><a href=#%e8%87%aa%e6%88%91%e4%b8%80%e8%87%b4%e6%80%a7-self-consistency aria-label="自我一致性 (Self-Consistency)">自我一致性 (Self-Consistency)</a></li><li><a href=#%e4%bb%bb%e5%8a%a1%e5%88%86%e8%a7%a3 aria-label=任务分解>任务分解</a></li></ul></li><li><a href=#%e7%ac%ac%e5%9b%9b%e6%ad%a5%e5%a2%9e%e5%bc%ba%e8%83%bd%e5%8a%9b%e5%92%8c%e6%8e%a7%e5%88%b6 aria-label=第四步：增强能力和控制>第四步：增强能力和控制</a><ul><li><a href=#%e7%b3%bb%e7%bb%9f%e6%8f%90%e7%a4%ba-system-prompt-%e5%92%8c%e8%a7%92%e8%89%b2 aria-label="系统提示 (System Prompt) 和角色">系统提示 (System Prompt) 和角色</a></li><li><a href=#%e6%a3%80%e7%b4%a2%e5%a2%9e%e5%bc%ba-rag aria-label="检索增强 (RAG)">检索增强 (RAG)</a></li><li><a href=#%e6%b8%a9%e5%ba%a6-temperature-%e5%92%8c-top_p aria-label="温度 (Temperature) 和 Top_p">温度 (Temperature) 和 Top_p</a></li></ul></li><li><a href=#%e5%8f%82%e8%80%83%e8%b5%84%e6%96%99 aria-label=参考资料>参考资料</a></li></ul></li></ul></div></details></div><div class=post-content><h2 id=掌握-llm-提示词的艺术>掌握 LLM 提示词的艺术<a hidden class=anchor aria-hidden=true href=#掌握-llm-提示词的艺术>#</a></h2><p>像 GPT-4 和 Claude 这样的大型语言模型 (LLM) 拥有非凡的能力。然而，要释放它们的全部潜力，需要通过精心设计的提示词 (prompts) 进行有效沟通。本指南深入探讨了提示工程 (prompt engineering) 的艺术，提供了一个从基本原则到高级技巧的分步方法，以驾驭 LLM 的真正力量。</p><h3 id=第一步选择最佳模型>第一步：选择最佳模型<a hidden class=anchor aria-hidden=true href=#第一步选择最佳模型>#</a></h3><ul><li><p><strong>最新且最强：</strong> 像 GPT-4 Turbo 这样的较新模型相比 GPT-3.5 Turbo 等前代产品提供了显著优势，包括更流畅的自然语言理解能力。对于较简单的任务，通过大量的提示工程来弥补模型能力的必要性可能会降低。</p></li><li><p><strong>基准测试：</strong> 利用 <a href=https://chat.lmsys.org/?leaderboard>LLM 排行榜</a> 和基准测试结果等资源来比较模型，并找出最适合你特定需求的模型。</p></li></ul><p><img alt=image loading=lazy src=https://github.com/zhoukuncheng/zhoukuncheng.github.io/assets/5327960/84e5da2a-f2ef-49b2-9137-eef2b8aaa9ed></p><p><strong>示例：</strong></p><ul><li>对于细致入微的语言翻译，GPT-4 Turbo 的上下文理解能力可能优于旧模型。</li><li>对于既需要能力又需要速度的任务，Llama-3-70b 开源模型是一个绝佳的选择。</li></ul><h3 id=第二步建立清晰的沟通>第二步：建立清晰的沟通<a hidden class=anchor aria-hidden=true href=#第二步建立清晰的沟通>#</a></h3><h4 id=清晰度和具体性>清晰度和具体性<a hidden class=anchor aria-hidden=true href=#清晰度和具体性>#</a></h4><ul><li><p><strong>明确的指令：</strong> 将 LLM 视为通过需要清晰指导的合作者。明确定义任务、期望的结果、格式、风格和输出长度，避免歧义。</p></li><li><p><strong>上下文背景：</strong> 提供相关的背景信息和语境，以引导 LLM 做出期望的回应，同时考虑目标受众和目的。</p></li><li><p><strong>关注点分离：</strong> 使用 <code>###</code> 或 <code>"""</code> 将指令与上下文内容清晰地分隔开。</p></li><li><p><strong>以示例为向导：</strong> 用精选的示例来演示期望的输出格式和风格。</p></li><li><p><strong>线索提示：</strong> 使用短语如 &ldquo;Key points:"（关键点：）、&ldquo;Summary:"（摘要：）或 &ldquo;Code:"（代码：）来指示期望的输出格式。</p></li></ul><p><strong>示例：</strong></p><ul><li>不要只说 &ldquo;写一篇博客文章&rdquo;，而应指定 &ldquo;写一篇关于可再生能源影响的 500 字博客文章，目标受众是行业专业人士。&rdquo;</li><li>对于诗歌生成任务，你可以指定期望的基调、韵律和主题。</li></ul><h4 id=少样本学习-few-shot-learning>少样本学习 (Few-Shot Learning)<a hidden class=anchor aria-hidden=true href=#少样本学习-few-shot-learning>#</a></h4><p>提供几个展示了期望输出格式和风格的示例，以减少歧义并设定清晰的预期。</p><p><strong>示例：</strong></p><ul><li><p><strong>提示：</strong> 将这些句子翻译成西班牙语：</p><ul><li>&ldquo;The cat sat on the mat.&rdquo; - &ldquo;El gato se sentó en la alfombra.&rdquo;</li><li>&ldquo;The dog barked at the mailman.&rdquo; - &ldquo;El perro ladró al cartero.&rdquo;</li><li>&ldquo;The children played in the park.&rdquo;</li></ul></li><li><p><strong>期望输出：</strong> &ldquo;Los niños jugaron en el parque.&rdquo;</p></li><li><p><strong>提示：</strong> 以风趣迷人的风格撰写产品描述：</p><ul><li><strong>产品：</strong> 降噪耳机</li><li><strong>描述：</strong> &ldquo;带上这款降噪耳机，让世界静音，迷失在你自己的声景中。这是逃离日常琐事或专注于工作的完美之选。&rdquo;</li><li><strong>产品：</strong> 旅行背包</li><li><strong>描述：</strong> &ldquo;这款旅行背包是你终极的冒险伴侣。凭借其宽敞的隔层和耐用的设计，它已准备好与你一起探索世界。&rdquo;</li><li><strong>产品：</strong> 智能手表</li><li><strong>描述：</strong></li></ul></li><li><p><strong>期望输出：</strong> &ldquo;这就不仅仅是一块计时的表；它是你的私人助理、健身追踪器和通知中心，所有这些都包裹在一个时尚的设计中。&rdquo;</p></li></ul><h3 id=第三步引导-llm-的思维过程>第三步：引导 LLM 的思维过程<a hidden class=anchor aria-hidden=true href=#第三步引导-llm-的思维过程>#</a></h3><h4 id=思维链-chain-of-thought-cot-提示>思维链 (Chain-of-Thought, CoT) 提示<a hidden class=anchor aria-hidden=true href=#思维链-chain-of-thought-cot-提示>#</a></h4><p>对于复杂的推理任务，引导 LLM 一步步地完成思维过程，鼓励它分解问题并生成导致答案的逻辑推理步骤序列。</p><p><strong>示例：</strong></p><ul><li><p><strong>问题：</strong> 约翰有 5 个苹果，给了玛丽 2 个，然后又买了 5 个。他现在有多少个苹果？</p></li><li><p><strong>CoT 提示：</strong> &ldquo;约翰开始有 5 个苹果。给了玛丽 2 个后，他还剩 3 个。又买了 5 个，让他有 3 + 5 = 8 个苹果。&rdquo;</p></li><li><p><strong>问题：</strong> 谁是 2000 年悉尼奥运会上获得奖牌最多的个人运动员？要在你的回答中采取循序渐进的方法，在分享以下格式的最终答案之前引用来源并给出推理：答案是：<code>&lt;名字></code></p></li><li><p><strong>CoT 提示：</strong></p></li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>步骤 1：确定悉尼奥运会的年份。悉尼奥运会于 2000 年举行。
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>步骤 2：查找在 2000 年悉尼奥运会上获得多枚奖牌的个人运动员名单。
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>根据奥运会官方网站，有几位个人运动员在 2000 年悉尼奥运会上赢得了多枚奖牌。一些著名的名字包括：
</span></span><span class=line><span class=cl>• 伊恩·索普 (Ian Thorpe) (澳大利亚) - 3 金, 2 银, 0 铜
</span></span><span class=line><span class=cl>• 彼得·范·登·霍根班德 (Pieter van den Hoogenband) (荷兰) - 2 金, 0 银, 2 铜
</span></span><span class=line><span class=cl>• 伦尼·克雷泽尔堡 (Lenny Krayzelburg) (美国) - 3 金, 0 银, 0 铜
</span></span><span class=line><span class=cl>• 英格·德·布鲁因 (Inge de Bruijn) (荷兰) - 3 金, 1 银, 0 铜
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>步骤 3：确定奖牌最多的运动员。查看了 2000 年悉尼奥运会上获得多枚奖牌的个人运动员名单后，我们可以看到奖牌最多的运动员是来自澳大利亚的伊恩·索普，他总共获得了 5 枚奖牌（3 金和 2 银）。
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>因此，答案是：伊恩·索普。
</span></span></code></pre></div><h4 id=自我一致性-self-consistency>自我一致性 (Self-Consistency)<a hidden class=anchor aria-hidden=true href=#自我一致性-self-consistency>#</a></h4><p>生成多个输出并选择最一致或最频繁的响应，以减轻偏差并提高可靠性。</p><p><strong>示例：</strong></p><ul><li>当寻求历史事实时，生成多个解释并根据共识选择最频繁或看似准确的一个。</li><li>同样，对于像故事生成这样的创造性任务，生成多个草稿并选择最引人入胜或连贯的叙述可能是有益的。</li></ul><p><em>提示：</em></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>问：小树林里有 15 棵树。果园工人今天将在小树林里种树。等他们做完后，
</span></span><span class=line><span class=cl>将会有 21 棵树。果园工人今天种了多少棵树？
</span></span><span class=line><span class=cl>答：我们从 15 棵树开始。后来我们有 21 棵树。差值必定是他们种植的树的数量。
</span></span><span class=line><span class=cl>所以，他们一定种了 21 - 15 = 6 棵树。答案是 6。
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>问：如果停车场有 3 辆车，又来了 2 辆车，停车场里有多少辆车？
</span></span><span class=line><span class=cl>答：停车场里已经有 3 辆车了。又来了 2 辆。现在有 3 + 2 = 5 辆车。答案是 5。
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>问：利亚有 32 块巧克力，她姐姐有 42 块。如果她们吃了 35 块，她们总共还剩多少块？
</span></span><span class=line><span class=cl>答：利亚有 32 块巧克力，利亚的姐姐有 42 块。这意味着最初有 32 + 42 = 74
</span></span><span class=line><span class=cl>块巧克力。已经吃了 35 块。所以她们总共还有 74 - 35 = 39 块巧克力。答案是 39。
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>问：杰森有 20 根棒棒糖。他给了丹尼一些棒棒糖。现在杰森有 12 根棒棒糖。杰森给了丹尼多少根棒棒糖？
</span></span><span class=line><span class=cl>答：杰森有 20 根棒棒糖。因为他现在只有 12 根，他一定把剩下的给了丹尼。他给丹尼的棒棒糖数量一定是 20 - 12 = 8 根。答案是 8。
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>问：肖恩有五个玩具。圣诞节时，他从父母那里各得到了两个玩具。他现在有多少个玩具？
</span></span><span class=line><span class=cl>答：他有 5 个玩具。他从妈妈那里得到了 2 个，所以之后他有 5 + 2 = 7 个玩具。然后他又从爸爸那里得到了 2 个，所以总共他有 7 + 2 = 9 个玩具。答案是 9。
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>问：服务器机房有九台电脑。从周一到周四，每天安装五台以上的电脑。现在服务器机房有多少台电脑？
</span></span><span class=line><span class=cl>答：从周一到周四有 4 天。每天增加 5 台电脑。这意味着总共增加了 4 * 5 = 20 台电脑。开始时有 9 台电脑，所以现在有 9 + 20 = 29 台电脑。
</span></span><span class=line><span class=cl>答案是 29。
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>问：迈克尔有 58 个高尔夫球。周二，他丢了 23 个高尔夫球。周三，他又丢了 2 个。周三结束时他有多少个高尔夫球？
</span></span><span class=line><span class=cl>答：迈克尔最初有 58 个球。他在周二丢了 23 个，所以之后他有 58 - 23 = 35 个球。周三他又丢了 2 个，所以现在他有 35 - 2 = 33 个球。答案是 33。
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>问：奥利维亚有 23 美元。她买了五个百吉饼，每个 3 美元。她还剩多少钱？
</span></span><span class=line><span class=cl>答：她买了 5 个百吉饼，每个 3 美元。这意味着她花了 15 美元。她还剩 8 美元。
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>问：我 6 岁时，我妹妹是我年龄的一半。现在我 70 岁了，我妹妹多大？
</span></span><span class=line><span class=cl>答：
</span></span></code></pre></div><p><em>输出 1：</em></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>我 6 岁时，我妹妹是我年龄的一半，所以她是 3 岁。现在我 70 岁了，所以她是 70 - 3 = 67 岁。答案是 67。
</span></span></code></pre></div><p><em>输出 2：</em></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>当叙述者 6 岁时，他的妹妹是他年龄的一半，也就是 3 岁。现在叙述者 70 岁了，他的妹妹应该是 70 - 3 = 67 岁。答案是 67。
</span></span></code></pre></div><p><em>输出 3：</em></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>我 6 岁时，我妹妹是我年龄的一半，所以她是 3 岁。现在我 70 岁了，所以她是 70/2 = 35 岁。答案是 35。
</span></span></code></pre></div><h4 id=任务分解>任务分解<a hidden class=anchor aria-hidden=true href=#任务分解>#</a></h4><p>使用提示链 (prompt chaining) 等技术将复杂的任务分解为更小、更易于管理的子任务。</p><p><strong>示例：</strong></p><ul><li><p>要解决一个复杂的数学问题，首先让 LLM 识别问题类型，然后逐步解决每个部分，最后组合各部分得出解决方案。</p></li><li><p><strong>代码生成的提示链：</strong></p><ol><li><strong>提示 1：</strong> &ldquo;编写一个 Python 函数，该函数接收一个数字列表作为输入。&rdquo;</li><li><strong>提示 2（基于提示 1 的输出）：</strong> &ldquo;修改该函数以计算列表中所有数字的总和。&rdquo;</li><li><strong>提示 3（基于提示 2 的输出）：</strong> &ldquo;向该函数添加功能，以返回列表中数字的平均值。&rdquo;</li></ol></li></ul><h3 id=第四步增强能力和控制>第四步：增强能力和控制<a hidden class=anchor aria-hidden=true href=#第四步增强能力和控制>#</a></h3><h4 id=系统提示-system-prompt-和角色>系统提示 (System Prompt) 和角色<a hidden class=anchor aria-hidden=true href=#系统提示-system-prompt-和角色>#</a></h4><ul><li><p><strong>系统提示：</strong> 定义 LLM 的行为、角色、个性和限制。</p></li><li><p><strong>角色分配：</strong> 分配特定角色以聚焦回答并定制语言风格。</p></li></ul><p><strong>示例：</strong></p><ul><li>&ldquo;你是一位友好的营养师，正在为一位麸质过敏的人提供均衡的饮食计划。&rdquo;</li><li>&ldquo;你是一位经验丰富的旅行向导，正在创建一个为期一周的探索罗马历史古迹的行程。&rdquo;</li></ul><h4 id=检索增强-rag>检索增强 (RAG)<a hidden class=anchor aria-hidden=true href=#检索增强-rag>#</a></h4><ul><li><strong>RAG：</strong> 将 LLM 与外部知识源（如数据库或 API）结合，以提高准确性和获取最新信息。</li></ul><p><strong>示例：</strong></p><ul><li>&ldquo;使用来自 XYZ API 的当前股市数据，分析并预测下周科技股的趋势。&rdquo;</li><li>&ldquo;从科学数据库访问有关气候变化的最新研究论文，并总结主要发现和提出的解决方案。&rdquo;</li></ul><h4 id=温度-temperature-和-top_p>温度 (Temperature) 和 Top_p<a hidden class=anchor aria-hidden=true href=#温度-temperature-和-top_p>#</a></h4><ul><li><p><strong>Temperature：</strong> 控制输出的随机性和创造性。</p></li><li><p><strong>Top_p：</strong> 调整下一个 token 的概率分布，以影响生成文本的多样性。</p></li></ul><p><strong>示例：</strong></p><ul><li>对于创意写作，较高的温度鼓励更多样化和意想不到的情节转折。对于事实报告，较低的温度确保信息更加直接和一致。</li><li>对于生成不同的创意文本格式，如诗歌、剧本或乐曲，调整温度和 top_p 可以导致所选格式内的风格和结构多样化。</li></ul><h3 id=参考资料>参考资料<a hidden class=anchor aria-hidden=true href=#参考资料>#</a></h3><p><a href=https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering>https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/advanced-prompt-engineering</a><br><a href=https://platform.openai.com/docs/guides/prompt-engineering>https://platform.openai.com/docs/guides/prompt-engineering</a><br><a href=https://docs.anthropic.com/claude/docs/prompt-engineering>https://docs.anthropic.com/claude/docs/prompt-engineering</a><br><a href=https://www.promptingguide.ai/>https://www.promptingguide.ai/</a></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://zhoukuncheng.github.io/zh/tags/llm/>LLM</a></li><li><a href=https://zhoukuncheng.github.io/zh/tags/prompt-engineering/>Prompt Engineering</a></li></ul></footer><script src=https://giscus.app/client.js data-repo=zhoukuncheng/zhoukuncheng.github.io data-repo-id="MDEwOlJlcG9zaXRvcnkyODIxMTA1OTU=" data-category=General data-category-id=DIC_kwDOENCqg84Cexta data-mapping=og:title data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-theme=purple_dark data-lang=en crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2025 <a href=https://zhoukuncheng.github.io/zh/>zhoukuncheng's Personal Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script></body></html>